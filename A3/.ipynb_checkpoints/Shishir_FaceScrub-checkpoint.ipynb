{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-448e5a908fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-57bd79de74ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"-1\"\u001b[0m \u001b[1;31m#for training on gpu/cpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #for training on gpu/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"data.npy\"\n",
    "target_path=\"target.npy\"\n",
    "task=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_segmentation(data_path, target_path, task):\n",
    "    # task = 0 >> select the name ID targets for face recognition task\n",
    "    # task = 1 >> select the gender ID targets for gender recognition task\n",
    "    data = np.load(data_path)/255\n",
    "    data = np.reshape(data, [-1, 32*32])\n",
    "    target = np.load(target_path)\n",
    "    np.random.seed(45689)\n",
    "    rnd_idx = np.arange(np.shape(data)[0])\n",
    "    np.random.shuffle(rnd_idx)\n",
    "    trBatch = int(0.8*len(rnd_idx))\n",
    "    validBatch = int(0.1*len(rnd_idx))\n",
    "    trainData, validData, testData = data[rnd_idx[1:trBatch],:], \\\n",
    "                                    data[rnd_idx[trBatch+1:trBatch + validBatch],:],\\\n",
    "                                    data[rnd_idx[trBatch + validBatch+1:-1],:]\n",
    "    trainTarget, validTarget, testTarget = target[rnd_idx[1:trBatch], task], \\\n",
    "                                            target[rnd_idx[trBatch+1:trBatch + validBatch], task],\\\n",
    "                                            target[rnd_idx[trBatch + validBatch + 1:-1], task]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, validData, testData, trainTarget, validTarget, testTarget=data_segmentation(data_path, target_path, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The name (ID) of the actors: ‘Lorraine Bracco’, ‘Gerard Butler’, ‘Peri Gilpin’, ‘Angie Harmon’, ‘Daniel Radcliffe’, and ‘Michael Vartan’ are encoded as ‘0’, ‘1’, ‘2’, ‘3’, ‘4’, and ‘5’,respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-55f078e058dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Lorraine Bracco\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Gerard Butler\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Peri Gilpin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Angie Harmon\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Daniel Radcliffe\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Michael Vartan\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = [\"Lorraine Bracco\", \"Gerard Butler\", \"Peri Gilpin\", \"Angie Harmon\", \"Daniel Radcliffe\",\"Michael Vartan\"]\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "columns = 5\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = trainData[i-1]*255\n",
    "    ax1 = fig.add_subplot(rows, columns, i)\n",
    "    ax1.set_title(class_names[trainTarget[i-1]])\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    plt.imshow(img.reshape((32, 32)), cmap='gray')\n",
    "    plt.grid\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(trainTarget[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are provided withtwo .npy files which have 936 rows of images and labels, and you should divide the dataset into 80/10/10% for training, validation and test, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training-set:\t\t747\n",
      "- Test-set:\t\t93\n",
      "- Validation-set:\t92\n"
     ]
    }
   ],
   "source": [
    "print(\"- Training-set:\\t\\t{}\".format(len(trainData)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(testData)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(validData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution\n",
    "\n",
    "Michael Vartan has biased data. Data is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = trainTarget\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(a, bins = [0,1,2,3,4,5]) \n",
    "plt.title(\"histogram\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-HOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (747, 6)\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((trainTarget.size, trainTarget.max()+1))\n",
    "b[np.arange(trainTarget.size),trainTarget] = 1\n",
    "trainLabel=b\n",
    "print ('Training set', trainLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (92, 6)\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((validTarget.size, validTarget.max()+1))\n",
    "b[np.arange(validTarget.size),validTarget] = 1\n",
    "validLabel=b\n",
    "print ('Training set', validLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (93, 6)\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((testTarget.size, testTarget.max()+1))\n",
    "b[np.arange(testTarget.size),testTarget] = 1\n",
    "testLabel=b\n",
    "print ('Training set', testLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: Peri Gilpin)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(trainData[0], (32,32))\n",
    "curr_lbl = np.argmax(trainLabel[0,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(class_names[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(testData[0], (32,32))\n",
    "curr_lbl = np.argmax(testLabel[0,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(class_names[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAIN  TASK-0   \n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp68ctoahz\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmp68ctoahz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D5333F0160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp1opib6ve\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmp1opib6ve', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D5333F0550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-13-5521fbc17010>:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-5521fbc17010>:25: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-5521fbc17010>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-13-5521fbc17010>:39: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp1opib6ve\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.7557647070554838, step = 1\n",
      "INFO:tensorflow:global_step/sec: 15.0418\n",
      "INFO:tensorflow:loss = 0.7481685328188907, step = 101 (6.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6687\n",
      "INFO:tensorflow:loss = 0.3158201309567134, step = 201 (6.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0796\n",
      "INFO:tensorflow:loss = 0.10944930337530007, step = 301 (6.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6888\n",
      "INFO:tensorflow:loss = 0.006102942685662929, step = 401 (6.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0667\n",
      "INFO:tensorflow:loss = 0.047506683393095814, step = 501 (6.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0438\n",
      "INFO:tensorflow:loss = 0.010054857805691148, step = 601 (6.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.954\n",
      "INFO:tensorflow:loss = 0.003827944581564017, step = 701 (6.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7454\n",
      "INFO:tensorflow:loss = 0.009992470536738827, step = 801 (6.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.825\n",
      "INFO:tensorflow:loss = 0.0009541345856566355, step = 901 (6.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8131\n",
      "INFO:tensorflow:loss = 0.002962691190283804, step = 1001 (6.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1838\n",
      "INFO:tensorflow:loss = 0.000525134551783031, step = 1101 (6.586 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1168 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp1opib6ve\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:15:56Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp1opib6ve\\model.ckpt-1168\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:15:59\n",
      "INFO:tensorflow:Saving dict for global step 1168: accuracy = 0.89, global_step = 1168, loss = 0.64895093\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1168: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp1opib6ve\\model.ckpt-1168\n",
      "INFO:tensorflow:Loss for final step: 0.0023358596862993962.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp68ctoahz, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:16:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:16:01\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.17204301, global_step = 0, loss = 1.8352581\n",
      "Testing Accuracy: 0.17204301\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 32\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1024 \n",
    "num_classes = 6 \n",
    "dropout = 0.5 # Dropout, probability to drop a unit\n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "\n",
    "        # Data input is a 1-D vector of 1024 features (32*32 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x_dict, shape=[-1, 32, 32, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 3\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 3, 2)\n",
    "\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 384)\n",
    "        \n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc2 = tf.layers.dense(fc1, 192)\n",
    "        \n",
    "        \n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc3 = tf.layers.dropout(fc2, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc3, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
    "                            is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
    "                           is_training=False)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=trainData, y=trainTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Define the input function for validation\n",
    "valid_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=validData, y=validTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input_fn,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = valid_fn,\n",
    "    throttle_secs=120,\n",
    "    start_delay_secs=120,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=testData, y=testTarget,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAIN  TASK-0   \n",
    "learning_rate = 0.0001\n",
    "num_steps = 2000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpvux5xp77\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmpvux5xp77', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D535CADC18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp47gcho8f\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmp47gcho8f', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D535CADD30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp47gcho8f\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.9917188445214071, step = 1\n",
      "INFO:tensorflow:global_step/sec: 14.92\n",
      "INFO:tensorflow:loss = 1.316606105117708, step = 101 (6.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4521\n",
      "INFO:tensorflow:loss = 0.8542268681992987, step = 201 (6.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5812\n",
      "INFO:tensorflow:loss = 0.48436373992387927, step = 301 (6.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.1438\n",
      "INFO:tensorflow:loss = 0.2509260220628181, step = 401 (5.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0733\n",
      "INFO:tensorflow:loss = 0.19406563180151346, step = 501 (5.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1838\n",
      "INFO:tensorflow:loss = 0.1797180500322063, step = 601 (6.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4826\n",
      "INFO:tensorflow:loss = 0.1819022082967175, step = 701 (5.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0701\n",
      "INFO:tensorflow:loss = 0.1901077215054721, step = 801 (5.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9889\n",
      "INFO:tensorflow:loss = 0.05712679497179414, step = 901 (5.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.1091\n",
      "INFO:tensorflow:loss = 0.053360890031811964, step = 1001 (5.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3856\n",
      "INFO:tensorflow:loss = 0.04436446567571894, step = 1101 (5.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1168 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp47gcho8f\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:17:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp47gcho8f\\model.ckpt-1168\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:17:15\n",
      "INFO:tensorflow:Saving dict for global step 1168: accuracy = 0.815625, global_step = 1168, loss = 0.5317729\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1168: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp47gcho8f\\model.ckpt-1168\n",
      "INFO:tensorflow:Loss for final step: 0.01747679119471331.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpvux5xp77, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:17:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:17:16\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.1827957, global_step = 0, loss = 1.8139461\n",
      "Testing Accuracy: 0.1827957\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "num_steps = 2000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=trainData, y=trainTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Define the input function for validation\n",
    "valid_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=validData, y=validTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input_fn,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = valid_fn,\n",
    "    throttle_secs=120,\n",
    "    start_delay_secs=120,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=testData, y=testTarget,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAIN  TASK-0   \n",
    "learning_rate = 0.001\n",
    "num_steps = 5000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp7wfzi0bd\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmp7wfzi0bd', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D5357F5710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpnwe6f96r\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmpnwe6f96r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D5357F5668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpnwe6f96r\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8773032865139672, step = 1\n",
      "INFO:tensorflow:global_step/sec: 16.725\n",
      "INFO:tensorflow:loss = 1.241540056383953, step = 101 (5.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5654\n",
      "INFO:tensorflow:loss = 0.8041596780534284, step = 201 (5.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.2216\n",
      "INFO:tensorflow:loss = 0.6765480139099157, step = 301 (5.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5469\n",
      "INFO:tensorflow:loss = 0.46596101762530695, step = 401 (5.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5756\n",
      "INFO:tensorflow:loss = 0.2943763081260087, step = 501 (6.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4363\n",
      "INFO:tensorflow:loss = 0.14467672431072165, step = 601 (5.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9405\n",
      "INFO:tensorflow:loss = 0.13830801644333213, step = 701 (5.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0799\n",
      "INFO:tensorflow:loss = 0.09362376869568251, step = 801 (5.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7683\n",
      "INFO:tensorflow:loss = 0.1471821007186159, step = 901 (5.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6176\n",
      "INFO:tensorflow:loss = 0.13094801417512503, step = 1001 (6.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.5748\n",
      "INFO:tensorflow:loss = 0.07361397686999382, step = 1101 (5.690 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1168 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpnwe6f96r\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:18:26Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpnwe6f96r\\model.ckpt-1168\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:18:28\n",
      "INFO:tensorflow:Saving dict for global step 1168: accuracy = 0.8128125, global_step = 1168, loss = 0.5534274\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1168: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpnwe6f96r\\model.ckpt-1168\n",
      "INFO:tensorflow:Loss for final step: 0.044223143278556996.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp7wfzi0bd, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:18:28Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:18:29\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.19354838, global_step = 0, loss = 1.8793281\n",
      "Testing Accuracy: 0.19354838\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "num_steps = 5000\n",
    "batch_size = 32\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=trainData, y=trainTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Define the input function for validation\n",
    "valid_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=validData, y=validTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input_fn,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = valid_fn,\n",
    "    throttle_secs=120,\n",
    "    start_delay_secs=120,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=testData, y=testTarget,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAIN  TASK-0   \n",
    "learning_rate = 0.001\n",
    "num_steps = 5000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpk346syrc\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmpk346syrc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D536510128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp9ba82r1e\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmp9ba82r1e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D5365100F0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp9ba82r1e\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8294954583455465, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.96477\n",
      "INFO:tensorflow:loss = 0.1759134094322991, step = 101 (14.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.74285\n",
      "INFO:tensorflow:loss = 0.015171658581171154, step = 201 (14.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 292 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp9ba82r1e\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:19:15Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp9ba82r1e\\model.ckpt-292\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:19:17\n",
      "INFO:tensorflow:Saving dict for global step 292: accuracy = 0.8369565, global_step = 292, loss = 0.8164533\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 292: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmp9ba82r1e\\model.ckpt-292\n",
      "INFO:tensorflow:Loss for final step: 0.010029446460207973.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpk346syrc, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:19:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:19:18\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.15053764, global_step = 0, loss = 1.8437403\n",
      "Testing Accuracy: 0.15053764\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=trainData, y=trainTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Define the input function for validation\n",
    "valid_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=validData, y=validTarget,\n",
    "    batch_size=batch_size, num_epochs=50, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input_fn,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = valid_fn,\n",
    "    throttle_secs=120,\n",
    "    start_delay_secs=120,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=testData, y=testTarget,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAIN  TASK-0   \n",
    "learning_rate = 0.01\n",
    "num_steps = 1000\n",
    "batch_size = 200\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpmq58uezz\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmpmq58uezz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D535F7D198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpujeep8dn\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\zorinDM\\\\AppData\\\\Local\\\\Temp\\\\tmpujeep8dn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D535F7D4A8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpujeep8dn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.8338641683640196, step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.88443\n",
      "INFO:tensorflow:loss = 0.26989564953081774, step = 101 (25.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.06801\n",
      "INFO:tensorflow:loss = 0.030439630895317222, step = 201 (24.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.122\n",
      "INFO:tensorflow:loss = 0.008415174756363828, step = 301 (24.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.05943\n",
      "INFO:tensorflow:loss = 0.003836172704673564, step = 401 (24.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.03112\n",
      "INFO:tensorflow:loss = 0.002540058307780525, step = 501 (24.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32198\n",
      "INFO:tensorflow:loss = 0.0015679155879562846, step = 601 (23.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.34698\n",
      "INFO:tensorflow:loss = 0.0009073002795548284, step = 701 (23.005 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 747 into C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpujeep8dn\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:22:22Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpujeep8dn\\model.ckpt-747\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:22:29\n",
      "INFO:tensorflow:Saving dict for global step 747: accuracy = 0.82608694, global_step = 747, loss = 0.8898781\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 747: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpujeep8dn\\model.ckpt-747\n",
      "INFO:tensorflow:Loss for final step: 0.0007654536954568168.\n",
      "INFO:tensorflow:Could not find trained model in model_dir: C:\\Users\\zorinDM\\AppData\\Local\\Temp\\tmpmq58uezz, running initialization to evaluate.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T09:22:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-09:22:31\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.12903225, global_step = 0, loss = 1.8204509\n",
      "Testing Accuracy: 0.12903225\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1024 \n",
    "num_classes = 6 \n",
    "dropout = 0.5 \n",
    "\n",
    "\n",
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "\n",
    "        # Data input is a 1-D vector of 1024 features (32*32 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x_dict, shape=[-1, 32, 32, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 3\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 3, 2)\n",
    "\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 384)\n",
    "        \n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc2 = tf.layers.dense(fc1, 192)\n",
    "        \n",
    "        \n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc3 = tf.layers.dropout(fc2, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc3, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False,\n",
    "                            is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True,\n",
    "                           is_training=False)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op,\n",
    "                                  global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=trainData, y=trainTarget,\n",
    "    batch_size=batch_size, num_epochs=200, shuffle=True)\n",
    "\n",
    "# Define the input function for validation\n",
    "valid_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=validData, y=validTarget,\n",
    "    batch_size=batch_size, num_epochs=200, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = input_fn,\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = valid_fn,\n",
    "    throttle_secs=120,\n",
    "    start_delay_secs=120,\n",
    ")\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=testData, y=testTarget,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = model.evaluate(input_fn)\n",
    "\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: ['ConvNet/conv2d/bias', 'ConvNet/conv2d/bias/Adam', 'ConvNet/conv2d/bias/Adam_1', 'ConvNet/conv2d/kernel', 'ConvNet/conv2d/kernel/Adam', 'ConvNet/conv2d/kernel/Adam_1', 'ConvNet/dense/bias', 'ConvNet/dense/bias/Adam', 'ConvNet/dense/bias/Adam_1', 'ConvNet/dense/kernel', 'ConvNet/dense/kernel/Adam', 'ConvNet/dense/kernel/Adam_1', 'ConvNet/dense_1/bias', 'ConvNet/dense_1/bias/Adam', 'ConvNet/dense_1/bias/Adam_1', 'ConvNet/dense_1/kernel', 'ConvNet/dense_1/kernel/Adam', 'ConvNet/dense_1/kernel/Adam_1', 'ConvNet/dense_2/bias', 'ConvNet/dense_2/bias/Adam', 'ConvNet/dense_2/bias/Adam_1', 'ConvNet/dense_2/kernel', 'ConvNet/dense_2/kernel/Adam', 'ConvNet/dense_2/kernel/Adam_1', 'beta1_power', 'beta2_power', 'global_step']\n",
      "[-0.00926375 -0.0036693   0.01338843 -0.01422129  0.03989397  0.04974192\n",
      "  0.05057328  0.01737685 -0.01694385 -0.00832147 -0.01364759  0.01490985\n",
      " -0.01247925 -0.0161253   0.01008508 -0.0014864  -0.00697283  0.05503672\n",
      "  0.00288403  0.00951609  0.03531757  0.00405214  0.0552086  -0.00720992\n",
      " -0.01769609 -0.00899315 -0.01253547  0.01699496 -0.0013095  -0.01217396\n",
      " -0.00393151 -0.00863157]\n",
      "[ 1.32757250e-03 -6.23903915e-04 -9.17004163e-04 -7.33491587e-06\n",
      "  6.47687319e-04 -3.69075349e-03  7.24376630e-04 -3.13840911e-04\n",
      " -3.54775177e-05  4.43941245e-05 -5.62829907e-05  1.09165913e-04\n",
      " -5.35383481e-05  7.63259050e-04 -1.08283403e-03 -1.95454860e-04\n",
      " -1.24073443e-04  1.04424994e-03 -1.17004059e-04  4.78884038e-04\n",
      "  1.12559783e-03 -6.50590552e-04 -2.10881083e-03 -1.57802858e-04\n",
      " -4.54217792e-06 -1.20622632e-05 -2.08662166e-05  5.61776751e-04\n",
      " -1.55803857e-03  1.28788432e-04 -6.37224154e-04 -5.34525369e-05]\n",
      "[0.01700233 0.00644529 0.00186383 0.00460041 0.00762633 0.02467281\n",
      " 0.0130476  0.00607786 0.00694085 0.00356178 0.00470247 0.00305051\n",
      " 0.00550669 0.01441752 0.00174031 0.00482394 0.00326208 0.009428\n",
      " 0.00227204 0.00711037 0.0234227  0.00173227 0.01080774 0.00258104\n",
      " 0.00488249 0.00221923 0.00532227 0.00506039 0.01121098 0.00723866\n",
      " 0.00607415 0.00163187]\n",
      "[[[[ 0.03212038  0.0536956  -0.01269295 -0.06857531  0.06427455\n",
      "    -0.00999738 -0.01030168  0.03210077  0.050638    0.05584317\n",
      "     0.06067143 -0.08858383  0.05980525 -0.04126641  0.03859193\n",
      "     0.00422814  0.04071439  0.07421119 -0.05187604 -0.12787348\n",
      "     0.08517978  0.05719714  0.12814429 -0.02131172  0.01734741\n",
      "     0.0279223  -0.04551439 -0.02554086 -0.08895264  0.07079295\n",
      "     0.03435493  0.04718807]]\n",
      "\n",
      "  [[ 0.04944641  0.05575001  0.0115458  -0.00403459  0.06916498\n",
      "    -0.08915313 -0.08734981  0.0912373   0.01422449  0.03813746\n",
      "    -0.08739971 -0.01774992 -0.06025726  0.05685338 -0.10625942\n",
      "     0.0713617   0.05494833 -0.01591472 -0.04537969 -0.06106278\n",
      "     0.04688676  0.06554482  0.02611397  0.02361962 -0.10179703\n",
      "    -0.05034489 -0.07417027  0.09078609 -0.09588161 -0.00614677\n",
      "    -0.09424283  0.04572827]]\n",
      "\n",
      "  [[ 0.00091974  0.01032901 -0.06533698 -0.04970077 -0.00231981\n",
      "    -0.03759805 -0.02245846  0.02400929 -0.0490143  -0.07187173\n",
      "     0.05108728 -0.02448034 -0.06426695  0.04932139 -0.05889888\n",
      "     0.01427744  0.00299667  0.02466494 -0.00348877  0.01167021\n",
      "    -0.02113089  0.06350082  0.02645007 -0.06738564  0.03231193\n",
      "    -0.02074654  0.02799296  0.11228024  0.06595996 -0.02301002\n",
      "     0.02514741 -0.03161326]]\n",
      "\n",
      "  [[ 0.05840567  0.03942599 -0.09148165 -0.04586468  0.05492093\n",
      "    -0.0549582  -0.14064244 -0.03563684 -0.0375263  -0.01874584\n",
      "    -0.00492718  0.02790776  0.01127824 -0.0212716   0.05428674\n",
      "     0.06060073 -0.02284449  0.13788094  0.06269513  0.11492035\n",
      "    -0.0530547   0.00296398  0.13176837 -0.04939078 -0.0515072\n",
      "     0.05341486  0.04170219  0.09707752  0.00116166  0.06840322\n",
      "    -0.01654511 -0.01684624]]\n",
      "\n",
      "  [[ 0.07563223  0.03508227  0.05373717 -0.05177202  0.05469582\n",
      "    -0.09701308 -0.03267965  0.02303216 -0.1007111   0.07103459\n",
      "    -0.0329378   0.07989209  0.02561473  0.07257726  0.03651619\n",
      "    -0.01408902  0.01181156  0.09260064  0.03219106  0.08355922\n",
      "    -0.02433963  0.00036776 -0.06617774  0.02922147 -0.02795605\n",
      "    -0.03639926 -0.00385007  0.10135362 -0.06572091  0.06798897\n",
      "    -0.07476185 -0.0675121 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.0780084   0.08646994  0.04860687  0.05824129 -0.1026296\n",
      "    -0.00489257  0.02796656  0.08061444 -0.06381171 -0.02494109\n",
      "     0.06865541  0.01798671 -0.01678015 -0.07594803  0.00227106\n",
      "    -0.05810362  0.06269025 -0.02215498  0.04087501 -0.11107841\n",
      "     0.05537126 -0.05532903  0.06106871  0.03342582 -0.05310093\n",
      "    -0.02086166  0.06647554  0.0068339  -0.04645333  0.06487501\n",
      "     0.02930336 -0.00709286]]\n",
      "\n",
      "  [[ 0.03289225  0.04501117 -0.00052329  0.01478192 -0.11131549\n",
      "    -0.01852559  0.06769492  0.10736106  0.00447168 -0.02001472\n",
      "     0.069986   -0.02854997  0.06363503 -0.00628202 -0.06330392\n",
      "    -0.05082355 -0.04000705 -0.09150794  0.04118355 -0.03414225\n",
      "    -0.01643855  0.02188175 -0.02328814 -0.01549877 -0.00369403\n",
      "    -0.00704353 -0.02993136 -0.04266373 -0.04186334  0.04827584\n",
      "    -0.07623687 -0.06606816]]\n",
      "\n",
      "  [[ 0.00294377 -0.04671924 -0.01222448 -0.056647   -0.00587568\n",
      "     0.05354428  0.07263968 -0.06251705  0.05423306 -0.00237584\n",
      "     0.03209566 -0.0651729  -0.03544343 -0.05028859 -0.00708982\n",
      "    -0.01345268 -0.00918083 -0.01858961  0.08397862 -0.03923263\n",
      "     0.06882705 -0.05759884  0.07302686 -0.02524658  0.06201521\n",
      "     0.0023419  -0.08545441 -0.05964711 -0.06288025  0.0696232\n",
      "    -0.00836897  0.03283597]]\n",
      "\n",
      "  [[ 0.06681439  0.05653709  0.06920934 -0.09038391 -0.01836269\n",
      "    -0.06555214 -0.0948542  -0.00772649 -0.04849008  0.00255841\n",
      "    -0.06637741  0.03596264  0.01382591  0.04688387 -0.08262054\n",
      "    -0.05346783  0.03496763 -0.04172612 -0.02813501  0.07457458\n",
      "    -0.04978784 -0.08970655 -0.09628369 -0.03622073  0.06716533\n",
      "     0.02249565  0.0351838   0.10897307  0.02506257 -0.00193778\n",
      "    -0.06821179  0.06903696]]\n",
      "\n",
      "  [[ 0.00645011  0.04023978 -0.04390445  0.06808725 -0.03973869\n",
      "     0.01396411 -0.05536497 -0.02044145 -0.04591501 -0.04241436\n",
      "    -0.08661629  0.01651495 -0.0393301  -0.03619432  0.05227112\n",
      "     0.08227001 -0.01367695  0.04988305 -0.06713094  0.06824692\n",
      "    -0.09171891  0.02010767 -0.12133235 -0.00016913  0.03675969\n",
      "    -0.07176729 -0.06374716 -0.05434562 -0.09519287  0.02637243\n",
      "     0.02256155  0.01718696]]]\n",
      "\n",
      "\n",
      " [[[-0.04401682  0.06573494 -0.06099404  0.05315337  0.05536537\n",
      "     0.01699827 -0.0075767   0.07432182  0.07360152 -0.03486306\n",
      "    -0.09431492 -0.01816721 -0.02008605  0.04231057  0.01421004\n",
      "     0.0322235  -0.01014314 -0.08775599  0.02314919 -0.04146773\n",
      "     0.06312936  0.00757098 -0.09631914 -0.03692029  0.05374694\n",
      "    -0.09117899 -0.00121646  0.00113147 -0.02067853 -0.01917897\n",
      "     0.0367244  -0.05220409]]\n",
      "\n",
      "  [[-0.04867123 -0.04184228 -0.08895096 -0.04022905 -0.09514131\n",
      "    -0.03590749  0.0453531   0.06191163 -0.04180876  0.03072827\n",
      "     0.05441572 -0.05686336  0.04832475 -0.07699656  0.03079748\n",
      "    -0.09476689  0.06342319 -0.10201845  0.00090425 -0.04415608\n",
      "    -0.03945486  0.03986494 -0.12343166  0.01955692 -0.02255898\n",
      "    -0.00639302 -0.08081525  0.00788615  0.03352814 -0.0166478\n",
      "    -0.02501375  0.00309329]]\n",
      "\n",
      "  [[ 0.01934506  0.00873069 -0.03836012  0.06107423  0.00053763\n",
      "    -0.00257056 -0.04035887 -0.10147384  0.05817411  0.06540716\n",
      "     0.05416859 -0.00376815  0.05847961  0.00728465  0.05535392\n",
      "    -0.02556853  0.03442902 -0.07373889  0.04450312 -0.07065347\n",
      "     0.00310023  0.01701956  0.00640814  0.05383829 -0.02631092\n",
      "    -0.00768141  0.04402542  0.01639037  0.00496766 -0.0043412\n",
      "     0.04786627 -0.00707227]]\n",
      "\n",
      "  [[ 0.07414113 -0.08324108 -0.00176467  0.05518119  0.02181672\n",
      "     0.04573599  0.06756542 -0.02809103  0.05088382 -0.01196897\n",
      "     0.00235987 -0.05633236  0.0090388   0.07176397 -0.03544222\n",
      "    -0.07078131  0.03258898  0.01435527 -0.03190304  0.07305453\n",
      "    -0.08567783  0.01270022 -0.09868165  0.02612344 -0.03896589\n",
      "     0.06942584 -0.01870164  0.00862696 -0.03925515 -0.08834293\n",
      "    -0.04554544 -0.05244296]]\n",
      "\n",
      "  [[ 0.02400327 -0.05815198 -0.08909355  0.05769968  0.07782059\n",
      "    -0.01804287 -0.10512012  0.03887983  0.03999355 -0.08333492\n",
      "    -0.01269918  0.09671101 -0.0719158  -0.02849258  0.09080454\n",
      "     0.06122099 -0.07167725  0.05604444 -0.09267359  0.02898883\n",
      "    -0.0678891  -0.07848901 -0.00993091  0.02412101 -0.09649474\n",
      "    -0.00358233 -0.07437856 -0.05145801 -0.00452908  0.02401581\n",
      "     0.06638382  0.04542758]]]\n",
      "\n",
      "\n",
      " [[[-0.09507996 -0.07050235  0.0309026  -0.0340713  -0.07408469\n",
      "     0.11356376  0.03627492 -0.06288779  0.06153182  0.04612749\n",
      "    -0.07420634  0.10744895 -0.06362721  0.05488534 -0.06713084\n",
      "    -0.08171349 -0.06366022  0.01310851 -0.05250632 -0.03029427\n",
      "     0.07207108 -0.02027375  0.00780124 -0.02688638 -0.04215448\n",
      "    -0.0166439  -0.09133262 -0.01103    -0.01461529 -0.03073544\n",
      "    -0.09536651 -0.06043623]]\n",
      "\n",
      "  [[ 0.04359726 -0.0916389   0.07631546 -0.05077513 -0.07666893\n",
      "    -0.04767055 -0.03477818  0.05577418 -0.0042395   0.0260912\n",
      "     0.06371278  0.05469155  0.03621942  0.02610133  0.00771416\n",
      "     0.02130478 -0.03309905  0.09043193 -0.01025282 -0.03493031\n",
      "     0.07585899  0.08557343 -0.08307581  0.06008653  0.01578644\n",
      "    -0.0016353   0.06552837 -0.04669379  0.02554814 -0.07824751\n",
      "     0.00821232  0.04491776]]\n",
      "\n",
      "  [[-0.07231322  0.0519342   0.01687158  0.00194058 -0.09256757\n",
      "     0.02515311  0.10176697 -0.0441282  -0.01052751  0.00223516\n",
      "    -0.00996876  0.0513546   0.06609521 -0.08261677 -0.00934252\n",
      "    -0.08270552 -0.03019241 -0.02992344 -0.02931694  0.07930146\n",
      "     0.01174843  0.04898852  0.03330069 -0.08274412 -0.0648912\n",
      "    -0.00599895 -0.09009729 -0.03860381  0.08312719  0.01362567\n",
      "     0.07086318 -0.02454153]]\n",
      "\n",
      "  [[ 0.064079    0.04965738  0.05351554 -0.07205873  0.12035873\n",
      "     0.00820837  0.07415313  0.01697568 -0.00533856 -0.06364769\n",
      "     0.0376989  -0.08001949 -0.08978191 -0.02745237  0.05290624\n",
      "    -0.08892514 -0.09546318 -0.12560728  0.02553516  0.01558019\n",
      "    -0.00961023 -0.01861913  0.03616466 -0.03158407 -0.0450717\n",
      "    -0.00876511  0.06908123 -0.00969765  0.00196791 -0.07602442\n",
      "    -0.03107614 -0.00940568]]\n",
      "\n",
      "  [[-0.08720514 -0.00967233 -0.05888018 -0.06341356  0.0498015\n",
      "    -0.04312334 -0.07497743 -0.02981336  0.03564627 -0.08877406\n",
      "     0.00313212 -0.0693505  -0.03156731  0.06754978 -0.05410995\n",
      "     0.05298842  0.01681948 -0.08417805 -0.00876995  0.07456255\n",
      "    -0.0909304  -0.04751604 -0.04277835  0.05528856  0.02508412\n",
      "     0.01972592  0.02649279 -0.00162793  0.06873591  0.01324511\n",
      "     0.03714809 -0.09173205]]]\n",
      "\n",
      "\n",
      " [[[ 0.0141841  -0.04022518  0.06534803  0.0516338  -0.01439575\n",
      "     0.10056032  0.08176485 -0.06214473  0.02463084  0.03646495\n",
      "    -0.05453201  0.04744965 -0.01082582  0.05315363 -0.05118335\n",
      "     0.06797746 -0.05017851 -0.0054048   0.06108319 -0.10403633\n",
      "     0.08680696  0.04291715 -0.04519864 -0.07437144  0.0600708\n",
      "     0.04667378  0.06256217 -0.06182501  0.07495581 -0.00916368\n",
      "    -0.0259479   0.01707255]]\n",
      "\n",
      "  [[-0.03625771 -0.08941519  0.0387254  -0.08156525 -0.10683116\n",
      "    -0.03909254  0.10677913 -0.12470531 -0.01086575 -0.04497001\n",
      "     0.01475916  0.11120194 -0.00639263  0.01779721 -0.03917719\n",
      "     0.01366379 -0.06119113  0.07127985  0.08398446 -0.03633387\n",
      "     0.06709931 -0.08967028  0.03218566 -0.0287433  -0.04781118\n",
      "    -0.02446694  0.03770832 -0.09319377  0.0766945  -0.04532709\n",
      "    -0.0160622  -0.018635  ]]\n",
      "\n",
      "  [[-0.04568086 -0.03245114 -0.05446741  0.05779304 -0.04659987\n",
      "     0.08362364  0.05297192 -0.03435107 -0.03317469  0.01525871\n",
      "    -0.00036551  0.01959863 -0.00069252  0.07002224  0.098089\n",
      "     0.0306376   0.05058684 -0.02898317 -0.07805536  0.08084785\n",
      "     0.03128694 -0.04452455  0.10830455 -0.02192755  0.05501732\n",
      "    -0.05877098 -0.05525922 -0.09011703  0.0728437  -0.06089524\n",
      "     0.06604485 -0.02033694]]\n",
      "\n",
      "  [[ 0.06438038  0.00422722 -0.01735927  0.00321102  0.06463802\n",
      "     0.00739383 -0.05569604  0.0260676   0.036094   -0.03529275\n",
      "     0.00766498 -0.11629152 -0.03879995  0.04492992  0.03953641\n",
      "     0.03801681 -0.09025901  0.05918194 -0.04356713  0.07090018\n",
      "    -0.03365411  0.00101483 -0.0273665   0.01377802 -0.00282321\n",
      "     0.06148542  0.01020126  0.07382636  0.09010565  0.04383235\n",
      "     0.02894052 -0.01751826]]\n",
      "\n",
      "  [[-0.03127477 -0.03137771  0.06747887 -0.01490746  0.09572851\n",
      "    -0.00390785 -0.02035089 -0.0153128   0.02505757 -0.01118167\n",
      "    -0.09075988 -0.04248632  0.03813527  0.03249521 -0.05626256\n",
      "     0.0212461   0.05401842 -0.05831392 -0.06497347 -0.05018428\n",
      "    -0.06676432 -0.07689327  0.07555854 -0.02589657  0.04424053\n",
      "    -0.0628026   0.0346096  -0.00353974 -0.03290994  0.00813055\n",
      "     0.07271463  0.01619475]]]]\n",
      "[[[[ 7.81549130e-04 -5.81262684e-04 -3.14384723e-04 -9.32806914e-07\n",
      "     6.20217179e-04 -1.12056645e-03  1.05571610e-04 -3.93931472e-04\n",
      "    -6.49989870e-05  7.50207430e-05  4.69140656e-06  9.51974948e-05\n",
      "    -2.77769123e-05  3.76121738e-04 -4.42729535e-04 -9.02999669e-05\n",
      "    -8.01040533e-05  9.49441863e-04  2.34598144e-05  6.66599218e-04\n",
      "     3.57740900e-04 -3.87506350e-04 -1.78008141e-03 -1.10886365e-05\n",
      "    -2.14677653e-06 -1.80528287e-06 -2.74291637e-06  2.66694046e-04\n",
      "    -5.08437808e-04  9.13216848e-05 -2.83088047e-04 -2.89203155e-05]]\n",
      "\n",
      "  [[ 7.63875015e-04 -5.71419700e-04 -2.15104238e-04 -5.93354068e-07\n",
      "     6.21408060e-04 -8.08850682e-04  3.59201213e-04 -5.92822353e-04\n",
      "    -3.81279598e-05  8.51670588e-05 -9.23638742e-06  9.87450226e-05\n",
      "    -2.11478890e-05  3.68855739e-04 -2.07760658e-04 -1.07523565e-04\n",
      "    -8.18357198e-05  1.06254404e-03  4.55083328e-05  5.23695658e-04\n",
      "     4.54693703e-04 -3.94439383e-04 -1.68001112e-03 -6.95899562e-06\n",
      "    -9.48572965e-07 -1.46977903e-06 -1.46496769e-06  4.51798145e-05\n",
      "    -5.95052958e-04  1.00934074e-04 -2.07514051e-04 -1.58115631e-05]]\n",
      "\n",
      "  [[ 6.97335318e-04 -4.28717917e-04 -1.30242885e-04 -4.27923422e-07\n",
      "     6.73369061e-04 -5.17674951e-04  6.84713634e-04 -2.65232241e-04\n",
      "    -2.78316754e-05  8.40224683e-05 -2.37650719e-05  1.32057359e-04\n",
      "    -1.66368072e-05  3.64521991e-04 -3.73812195e-04 -1.29543289e-04\n",
      "    -6.48478311e-05  7.54297487e-04 -5.21575679e-05  2.70285706e-05\n",
      "     6.58426009e-04 -3.99682325e-04 -1.64431506e-03 -4.93073125e-06\n",
      "    -9.24853988e-07 -3.11238167e-06 -3.54675727e-06 -8.49750432e-05\n",
      "    -6.87915425e-04  8.70670841e-05 -2.14386266e-04 -3.97795654e-06]]\n",
      "\n",
      "  [[ 6.43468837e-04 -3.85250085e-04 -8.79074971e-05 -1.21937776e-07\n",
      "     4.81080349e-04 -3.28093789e-04  9.66745410e-04  1.73064472e-05\n",
      "     2.58491075e-05  5.52647336e-05 -1.67153396e-05  8.33412801e-05\n",
      "    -1.74664578e-05  3.39471193e-04 -5.94478880e-04 -1.59401092e-04\n",
      "    -5.83843862e-05  5.67617511e-04 -9.46062460e-05 -3.63417216e-04\n",
      "     8.61421214e-04 -3.58127685e-04 -1.22101267e-03 -1.82558142e-05\n",
      "    -4.03899238e-07 -5.05707783e-06 -7.16512273e-06 -6.70449552e-05\n",
      "    -6.46557023e-04  4.76866151e-05 -2.39096055e-04 -8.44412489e-07]]\n",
      "\n",
      "  [[ 6.45578290e-04 -3.18623560e-04 -2.30744581e-04 -1.01806031e-06\n",
      "     3.61559522e-04 -5.69745501e-04  1.02793791e-03 -1.97633519e-05\n",
      "     6.10874233e-05  4.56025883e-05 -1.67434511e-05  1.35742073e-04\n",
      "    -1.37239961e-05  3.30698632e-04 -6.27228596e-04 -2.10176902e-04\n",
      "    -5.85969194e-05  5.61005073e-04 -5.12819879e-05 -4.47359260e-04\n",
      "     1.03619030e-03 -3.53818094e-04 -8.28575609e-04 -6.04552584e-05\n",
      "     2.77743129e-07 -3.21148672e-06 -8.58942631e-06  9.88726877e-06\n",
      "    -5.32098151e-04  6.21185838e-05 -2.49695158e-04 -7.02344506e-07]]]\n",
      "\n",
      "\n",
      " [[[ 7.84000810e-04 -6.22552333e-04 -2.43187683e-04 -1.53937760e-06\n",
      "     9.38891358e-04 -1.23608511e-03 -1.71294063e-05 -5.69262254e-04\n",
      "    -9.20094505e-05  7.84029781e-05 -6.37141335e-06  9.47244290e-06\n",
      "    -2.76716667e-05  4.15169010e-04 -4.60509977e-04 -6.44799451e-05\n",
      "    -8.00427440e-05  1.01866409e-03 -5.47231072e-05  5.63321882e-04\n",
      "     2.04541065e-04 -2.77454495e-04 -1.57723026e-03 -9.47100611e-06\n",
      "    -9.56244579e-07 -1.45272829e-06 -3.28613024e-06  4.10737207e-04\n",
      "    -5.84211849e-04  7.86514907e-05 -2.82472185e-04 -1.06917483e-05]]\n",
      "\n",
      "  [[ 7.54301792e-04 -5.85837028e-04 -1.45698880e-04 -9.27669186e-07\n",
      "     9.43141370e-04 -1.03822296e-03  9.16672105e-05 -5.04135504e-04\n",
      "    -6.30957889e-05  8.51978478e-05 -2.72712185e-05  1.52510962e-04\n",
      "    -2.52609048e-05  4.09178143e-04 -3.10746921e-04 -3.65149487e-05\n",
      "    -7.93641957e-05  1.20760330e-03 -3.96144924e-05  3.44135432e-04\n",
      "     4.31250616e-04 -2.69211759e-04 -1.29796830e-03 -6.23709494e-06\n",
      "    -8.84850219e-07 -1.08888996e-06 -1.54473560e-06  2.59878460e-04\n",
      "    -6.23703506e-04  1.05814302e-04 -2.19697768e-04 -4.34589457e-06]]\n",
      "\n",
      "  [[ 7.08340898e-04 -4.28849930e-04 -1.15296090e-04 -6.87732094e-07\n",
      "     7.76054206e-04 -1.01208454e-03  3.18376384e-04  6.87021353e-05\n",
      "    -4.97940011e-05  8.31978800e-05 -2.63509036e-05  2.62794497e-04\n",
      "    -2.07684421e-05  4.13191807e-04 -4.66066940e-04 -5.31800863e-05\n",
      "    -7.18727554e-05  9.92166161e-04 -7.51643272e-05 -8.73092669e-06\n",
      "     7.36730597e-04 -2.28945603e-04 -1.24149481e-03 -7.18639149e-06\n",
      "    -1.33940849e-06 -3.22246524e-06 -3.40535755e-06  1.78608930e-04\n",
      "    -6.74053633e-04  1.05783222e-04 -2.31953305e-04 -2.21259345e-06]]\n",
      "\n",
      "  [[ 6.67443857e-04 -3.04478395e-04 -1.10734827e-04 -5.84251576e-07\n",
      "     4.95471327e-04 -7.65280714e-04  8.17288121e-04  1.96467293e-04\n",
      "    -2.33156698e-05  5.20080310e-05 -1.17867713e-05  1.46110598e-04\n",
      "    -1.43060823e-05  3.84008571e-04 -5.75291105e-04 -1.19836835e-04\n",
      "    -5.70312936e-05  8.05291105e-04 -5.69192614e-05 -3.86107873e-04\n",
      "     9.95116995e-04 -1.81089265e-04 -6.74351718e-04 -1.99321079e-05\n",
      "    -1.10868159e-06 -5.83149113e-06 -7.35105216e-06  1.73654521e-04\n",
      "    -6.14239096e-04  6.63435501e-05 -2.48018619e-04 -2.42287800e-06]]\n",
      "\n",
      "  [[ 6.50927358e-04 -2.26536917e-04 -1.51597171e-04 -1.31800045e-06\n",
      "     3.70881632e-04 -7.82378472e-04  1.15925330e-03  7.19757061e-05\n",
      "    -2.75867851e-06  3.94586912e-05 -1.67266956e-05  1.01786793e-04\n",
      "    -8.58543640e-06  3.51203981e-04 -6.73916541e-04 -2.17562941e-04\n",
      "    -4.80859136e-05  5.37716869e-04 -3.52792425e-05 -5.11644360e-04\n",
      "     1.14855781e-03 -2.10298422e-04 -3.66501025e-04 -6.13433639e-05\n",
      "    -8.00500746e-07 -3.36156877e-06 -7.66436291e-06  1.38595627e-04\n",
      "    -5.27111504e-04  9.04739911e-05 -3.06322347e-04 -6.53436032e-06]]]\n",
      "\n",
      "\n",
      " [[[ 7.71452634e-04 -4.51070072e-04 -2.02022005e-04 -1.85429026e-06\n",
      "     1.03538290e-03 -1.73883689e-03 -1.80787753e-04 -4.17021783e-04\n",
      "    -1.29356976e-04  7.48294842e-05  1.87888824e-06 -1.37057135e-04\n",
      "    -2.56416082e-05  4.30805298e-04 -5.53957796e-04 -2.12861563e-05\n",
      "    -5.52923941e-05  9.92888411e-04 -1.96276537e-05  4.31912057e-04\n",
      "     2.25414324e-04 -3.00443722e-04 -8.41845017e-04 -8.15177537e-06\n",
      "    -4.07344682e-07 -1.05140009e-06 -2.01177414e-06  5.77173175e-04\n",
      "    -8.80958458e-04  1.68330207e-04 -2.97582962e-04 -2.70040410e-06]]\n",
      "\n",
      "  [[ 7.57193741e-04 -4.27759270e-04 -1.19652972e-04 -9.25798208e-07\n",
      "     1.08127630e-03 -1.36833942e-03 -1.27049936e-04 -2.56372868e-04\n",
      "    -1.10131764e-04  7.29380840e-05 -2.16324129e-05  6.70756242e-05\n",
      "    -2.92301570e-05  4.09677039e-04 -6.51268459e-04  1.46865502e-05\n",
      "    -5.49746541e-05  1.07556335e-03 -4.24247068e-05  1.95507149e-04\n",
      "     4.37222992e-04 -3.35974986e-04 -7.07666907e-04 -9.03579430e-06\n",
      "    -2.94863449e-07 -9.28193706e-07 -1.79317913e-06  5.50080204e-04\n",
      "    -9.17421839e-04  2.20921639e-04 -3.06821875e-04 -1.27374763e-06]]\n",
      "\n",
      "  [[ 7.44337264e-04 -2.63640950e-04 -1.12315837e-04 -9.49314194e-07\n",
      "     8.24127077e-04 -1.34977484e-03  7.42743773e-05  2.03697651e-04\n",
      "    -1.02753879e-04  7.05626370e-05 -2.96802151e-05  2.08678591e-04\n",
      "    -2.47988788e-05  3.93564409e-04 -7.70006018e-04  1.92661684e-05\n",
      "    -5.86551539e-05  1.22929069e-03 -4.58229261e-05 -1.83644344e-05\n",
      "     6.79796572e-04 -2.68649845e-04 -8.56807925e-04 -1.02582289e-05\n",
      "    -5.75207320e-07 -3.13146304e-06 -2.74391109e-06  6.05642809e-04\n",
      "    -8.99900135e-04  2.43979780e-04 -3.50230348e-04 -1.59096017e-06]]\n",
      "\n",
      "  [[ 7.25275097e-04 -1.12941545e-04 -1.12362602e-04 -1.97850490e-06\n",
      "     4.46231957e-04 -1.36079159e-03  4.76569102e-04  2.46097173e-04\n",
      "    -1.08889670e-04  4.22487036e-05 -1.02859669e-05  2.57968031e-04\n",
      "    -9.05670896e-06  3.58743142e-04 -7.07541162e-04 -5.59190368e-05\n",
      "    -4.06122939e-05  1.14214987e-03 -1.76736286e-05 -3.90359777e-04\n",
      "     8.96310450e-04 -1.79905729e-04 -7.04143673e-04 -2.27772565e-05\n",
      "    -5.75614681e-07 -6.50100674e-06 -6.81872346e-06  5.66428142e-04\n",
      "    -7.92378467e-04  1.89955053e-04 -3.55430303e-04 -2.72779579e-06]]\n",
      "\n",
      "  [[ 7.05027840e-04 -7.93414739e-05 -9.53343171e-05 -1.18392174e-06\n",
      "     2.30817065e-04 -1.18831897e-03  8.94309519e-04  2.11752824e-04\n",
      "    -1.01702688e-04  3.34423151e-05 -1.89442921e-05  1.59091062e-04\n",
      "    -4.21785336e-06  3.32392829e-04 -7.41616273e-04 -1.80597565e-04\n",
      "    -3.34179600e-05  8.45974605e-04 -2.65472969e-05 -5.61952268e-04\n",
      "     1.07894299e-03 -1.41517094e-04 -5.74045012e-04 -6.86548321e-05\n",
      "    -1.59212149e-07 -4.02641598e-06 -7.39463557e-06  5.39142874e-04\n",
      "    -6.91070874e-04  1.75331790e-04 -3.95726334e-04 -9.90440693e-06]]]\n",
      "\n",
      "\n",
      " [[[ 8.18187761e-04 -1.28261213e-04 -3.57941864e-04 -1.85606150e-06\n",
      "     1.05311679e-03 -2.07201479e-03 -3.57598971e-04  9.15454686e-05\n",
      "    -1.41620497e-04  7.81966675e-05  9.54973968e-06 -3.08933485e-04\n",
      "    -2.00457977e-05  4.08060221e-04 -4.31646472e-04 -1.53817115e-05\n",
      "    -1.98523299e-05  7.79872017e-04 -3.60797451e-06  2.85770717e-04\n",
      "     2.46394202e-04 -3.32178266e-04 -3.99157701e-04 -8.54211501e-06\n",
      "    -5.68964457e-07 -1.08788564e-06 -2.10628250e-06  7.67508785e-04\n",
      "    -1.13961634e-03  2.92992929e-04 -2.92399013e-04 -2.79930456e-06]]\n",
      "\n",
      "  [[ 7.99507183e-04 -1.48679633e-04 -3.04747687e-04 -8.01192609e-07\n",
      "     1.17934902e-03 -1.51272846e-03 -2.42387507e-04  3.07990195e-04\n",
      "    -1.17321666e-04  7.21483422e-05 -1.41560864e-05 -2.91549131e-04\n",
      "    -2.67373538e-05  3.87749758e-04 -6.95193921e-04 -2.12463148e-05\n",
      "    -1.47139179e-05  5.84410366e-04 -2.43410439e-05  8.18738315e-05\n",
      "     3.72334543e-04 -3.68069948e-04 -7.46076339e-04 -1.24791384e-05\n",
      "    -5.15507881e-07 -8.47513728e-07 -3.15082852e-06  8.39482706e-04\n",
      "    -1.17085247e-03  3.15779061e-04 -3.54977941e-04 -2.76367956e-06]]\n",
      "\n",
      "  [[ 7.69012608e-04 -1.65153836e-04 -1.77859556e-04 -1.98353782e-06\n",
      "     8.76511161e-04 -1.55734346e-03  4.64077484e-06  3.86185143e-04\n",
      "    -1.07772776e-04  6.01294528e-05 -3.13714064e-05  9.20031420e-05\n",
      "    -2.33754522e-05  3.77964915e-04 -8.75204249e-04 -8.09620487e-06\n",
      "    -2.19076358e-05  8.97086170e-04  4.77373912e-06 -5.51567261e-05\n",
      "     5.65948687e-04 -2.88423131e-04 -1.30062380e-03 -9.26497912e-06\n",
      "    -9.05204548e-07 -2.11449738e-06 -1.47851689e-06  9.00045881e-04\n",
      "    -1.16379716e-03  3.24734454e-04 -4.33027708e-04 -3.40711303e-06]]\n",
      "\n",
      "  [[ 7.49920532e-04 -1.05203258e-04 -1.42070485e-04 -1.44744734e-06\n",
      "     3.95187931e-04 -1.60165279e-03  2.28963148e-04  2.39281537e-04\n",
      "    -1.11559036e-04  3.77050002e-05 -9.33148857e-06  5.64053978e-04\n",
      "    -5.65498762e-06  3.61342846e-04 -7.96127654e-04 -4.98543623e-05\n",
      "    -2.21738423e-05  1.09912876e-03  1.82011980e-05 -3.34417896e-04\n",
      "     7.90761499e-04 -1.99182886e-04 -1.25513331e-03 -2.69585252e-05\n",
      "    -4.82741496e-07 -5.19291206e-06 -7.48923379e-06  8.65544630e-04\n",
      "    -1.02953829e-03  2.81732746e-04 -4.45149583e-04 -3.29487552e-06]]\n",
      "\n",
      "  [[ 6.97962658e-04 -4.55426798e-05 -1.62735420e-04 -6.40159494e-07\n",
      "     1.24050160e-04 -1.38209687e-03  5.93032582e-04  1.81181019e-04\n",
      "    -1.08687344e-04  3.62331632e-05 -1.56487498e-05  5.10078063e-04\n",
      "    -4.72473585e-06  3.37004397e-04 -6.52191314e-04 -1.50144548e-04\n",
      "    -3.41067977e-05  9.57369529e-04 -1.17628132e-05 -6.02357769e-04\n",
      "     9.76568327e-04 -1.56809660e-04 -9.77844420e-04 -6.84333735e-05\n",
      "    -3.77487325e-07 -3.85563809e-06 -9.45912476e-06  7.89454216e-04\n",
      "    -9.18829477e-04  2.10203143e-04 -4.57441028e-04 -6.42558125e-06]]]\n",
      "\n",
      "\n",
      " [[[ 8.19228243e-04 -1.61293055e-04 -3.86121354e-04 -1.99412027e-06\n",
      "     1.02893093e-03 -2.17194240e-03 -3.90102103e-04  4.34837299e-04\n",
      "    -1.32373669e-04  7.42402326e-05 -2.20628960e-06 -2.92651530e-04\n",
      "    -2.51755230e-05  3.81057622e-04 -4.22998221e-04 -9.13470454e-05\n",
      "    -1.62880864e-05  4.35637950e-04 -3.28439018e-05  1.97383232e-04\n",
      "     2.75500158e-04 -2.39925326e-04 -8.97315619e-04 -8.54125591e-06\n",
      "    -7.96899974e-07 -2.15898303e-06 -6.34706928e-06  8.21539731e-04\n",
      "    -1.20492148e-03  2.48737625e-04 -3.00075380e-04 -4.08909631e-06]]\n",
      "\n",
      "  [[ 8.01725508e-04 -1.40930383e-04 -3.41793132e-04 -1.05295099e-06\n",
      "     1.01761978e-03 -1.67056623e-03 -2.37745820e-04  5.59496681e-04\n",
      "    -7.67732725e-05  6.24235439e-05 -2.45233525e-05 -3.35981162e-04\n",
      "    -2.89101299e-05  3.89653368e-04 -7.18435157e-04 -1.38221087e-04\n",
      "    -1.19973787e-05  2.51812101e-04 -6.07119710e-05  1.34002224e-05\n",
      "     2.52446866e-04 -2.42682387e-04 -1.42572866e-03 -1.14585469e-05\n",
      "    -1.33214890e-06 -1.24129803e-06 -3.84768293e-06  8.33422009e-04\n",
      "    -1.20168227e-03  2.52629845e-04 -3.64786999e-04 -2.96202034e-06]]\n",
      "\n",
      "  [[ 7.59654525e-04 -1.37687057e-04 -1.89096152e-04 -2.25291095e-06\n",
      "     7.44963327e-04 -1.71907654e-03 -1.56168034e-05  4.78928718e-04\n",
      "    -6.69311506e-05  4.60045945e-05 -3.43941924e-05  9.76222787e-05\n",
      "    -2.28459439e-05  3.86763730e-04 -9.23534632e-04 -1.61517488e-04\n",
      "    -2.36214011e-05  4.81553429e-04  6.12699459e-06 -1.42083711e-04\n",
      "     4.05941782e-04 -2.08156560e-04 -2.01711927e-03 -8.65095707e-06\n",
      "    -2.24713559e-06 -1.55274718e-06 -1.50342584e-06  7.45202608e-04\n",
      "    -1.19700390e-03  2.45305098e-04 -4.50038711e-04 -3.91639018e-06]]\n",
      "\n",
      "  [[ 7.39562615e-04 -1.38994207e-04 -1.90846671e-04 -9.99582325e-07\n",
      "     2.61954557e-04 -1.83127540e-03  2.64244645e-04  2.77265888e-04\n",
      "    -8.20451515e-05  3.92400321e-05 -1.30312845e-05  7.67404563e-04\n",
      "    -8.95783786e-06  3.75624237e-04 -8.72297220e-04 -1.98613555e-04\n",
      "    -2.78392664e-05  7.05370457e-04  2.97052291e-05 -3.38348747e-04\n",
      "     7.15796517e-04 -2.05216111e-04 -1.66138563e-03 -3.08886111e-05\n",
      "    -1.19461861e-06 -4.07764239e-06 -8.56187008e-06  5.64064737e-04\n",
      "    -1.06061180e-03  2.12444047e-04 -4.55138251e-04 -6.18648600e-06]]\n",
      "\n",
      "  [[ 7.05877105e-04 -6.14558946e-05 -2.44844977e-04 -6.25918334e-07\n",
      "    -1.05551484e-04 -1.78085502e-03  6.54985925e-04  1.30517392e-04\n",
      "    -9.35497134e-05  4.40523301e-05 -1.07158772e-05  7.99737071e-04\n",
      "    -8.11540273e-06  3.40858092e-04 -6.31819722e-04 -2.72068417e-04\n",
      "    -4.69665731e-05  7.89716196e-04  9.62714886e-06 -5.17391140e-04\n",
      "     9.34649700e-04 -1.22387018e-04 -1.19663168e-03 -6.04709829e-05\n",
      "    -1.10933812e-06 -3.57783434e-06 -1.15609351e-05  5.35362809e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    -9.41320662e-04  1.46554455e-04 -4.74029595e-04 -1.22295361e-05]]]]\n",
      "[[[[0.00568623 0.00246926 0.00047228 0.00147231 0.00159916 0.00445113\n",
      "    0.00576756 0.00338213 0.00245481 0.00134327 0.00166406 0.00096511\n",
      "    0.0018713  0.00412391 0.00023684 0.00144587 0.00126638 0.00142503\n",
      "    0.00076314 0.00169145 0.00995353 0.00070923 0.00321745 0.00081286\n",
      "    0.00158909 0.00070918 0.00150272 0.00182843 0.00249431 0.00267333\n",
      "    0.00185822 0.00061841]]\n",
      "\n",
      "  [[0.00586486 0.0024304  0.00038198 0.00140408 0.00164088 0.00347444\n",
      "    0.00569774 0.0034358  0.00238173 0.00129322 0.00168986 0.0009885\n",
      "    0.00182397 0.00450943 0.00020677 0.0015001  0.00130333 0.00136297\n",
      "    0.00079376 0.00175315 0.00963061 0.00069579 0.00293485 0.00080162\n",
      "    0.00161852 0.00070496 0.0014589  0.001996   0.00265996 0.00263876\n",
      "    0.00173743 0.00061509]]\n",
      "\n",
      "  [[0.0060368  0.00232253 0.00030558 0.00126616 0.00182912 0.00278834\n",
      "    0.00553995 0.00298562 0.0021954  0.00116798 0.00169499 0.00101631\n",
      "    0.00175291 0.00481634 0.00025066 0.00153559 0.00123483 0.00168711\n",
      "    0.00081391 0.00206008 0.00884617 0.00058955 0.00274813 0.00071865\n",
      "    0.00181197 0.00077777 0.00165153 0.00231372 0.00304234 0.00264427\n",
      "    0.00181306 0.00057839]]\n",
      "\n",
      "  [[0.00629516 0.00234891 0.00029795 0.00124687 0.00211448 0.00207896\n",
      "    0.0052876  0.00252489 0.00194246 0.00110608 0.00156442 0.00109357\n",
      "    0.00177449 0.00497    0.00037884 0.00161995 0.00115299 0.00232005\n",
      "    0.00076875 0.0025537  0.00824269 0.00046554 0.00243928 0.00074897\n",
      "    0.00181375 0.00081734 0.00181486 0.00253441 0.00295515 0.00279938\n",
      "    0.00178909 0.00053525]]\n",
      "\n",
      "  [[0.00608254 0.0022809  0.00033176 0.00138551 0.00231399 0.00186385\n",
      "    0.00511742 0.00228219 0.00176035 0.00110401 0.00143693 0.00115855\n",
      "    0.00175382 0.00496177 0.00051215 0.00168814 0.00110764 0.0027376\n",
      "    0.00069521 0.00272216 0.00826874 0.0004135  0.00214069 0.00088516\n",
      "    0.00169903 0.00072838 0.00172445 0.00239033 0.00267288 0.00283392\n",
      "    0.00175374 0.00046769]]]\n",
      "\n",
      "\n",
      " [[[0.005603   0.00237505 0.00048583 0.00169228 0.00148659 0.00497706\n",
      "    0.00621709 0.00326743 0.00247089 0.00127654 0.00170969 0.00097697\n",
      "    0.00192606 0.00408574 0.00022952 0.00130875 0.00125009 0.00119217\n",
      "    0.00085471 0.00169852 0.00992181 0.00063718 0.00262887 0.00083336\n",
      "    0.00169909 0.00066555 0.00167384 0.00190059 0.00279934 0.00266735\n",
      "    0.00191073 0.00055878]]\n",
      "\n",
      "  [[0.00577349 0.00226383 0.00038724 0.00156532 0.00154205 0.0038239\n",
      "    0.00625174 0.00318375 0.00247463 0.00126964 0.00182166 0.00099056\n",
      "    0.00204106 0.00426037 0.00022004 0.00128449 0.00129249 0.00110509\n",
      "    0.00087005 0.00173935 0.00981981 0.00062889 0.00238061 0.00083968\n",
      "    0.00177354 0.00070702 0.00150989 0.00191921 0.00298866 0.0026675\n",
      "    0.00182583 0.00058001]]\n",
      "\n",
      "  [[0.00609327 0.0021288  0.00032742 0.0014063  0.00175916 0.00320939\n",
      "    0.00589305 0.00259537 0.00241498 0.00118089 0.00178316 0.00098095\n",
      "    0.00195271 0.00462778 0.00026429 0.00134147 0.00124788 0.0014047\n",
      "    0.00084171 0.00194578 0.00919677 0.00052452 0.00225968 0.00080269\n",
      "    0.0019412  0.0008157  0.00159204 0.00216381 0.00324211 0.00263841\n",
      "    0.00189857 0.00059912]]\n",
      "\n",
      "  [[0.00643386 0.00214392 0.00032314 0.00140535 0.00207683 0.00234185\n",
      "    0.00541947 0.0021848  0.00217617 0.00105042 0.00156615 0.0010259\n",
      "    0.00181545 0.00499349 0.00035356 0.00150313 0.00117064 0.00194884\n",
      "    0.00071364 0.00244683 0.00846118 0.00040294 0.00190959 0.00083892\n",
      "    0.00194461 0.00085665 0.0017409  0.00243598 0.00314129 0.00269262\n",
      "    0.00190406 0.00058927]]\n",
      "\n",
      "  [[0.00610807 0.00210896 0.00031177 0.00157603 0.00232633 0.00200691\n",
      "    0.0052286  0.00199386 0.00198198 0.00098252 0.00139509 0.00112882\n",
      "    0.00167912 0.00489143 0.00049839 0.00171332 0.0010896  0.00244931\n",
      "    0.00060327 0.00272805 0.0083374  0.00036253 0.00181978 0.00094141\n",
      "    0.00178963 0.00074756 0.00163907 0.00227347 0.00280901 0.00275523\n",
      "    0.00196504 0.00053341]]]\n",
      "\n",
      "\n",
      " [[[0.0048765  0.00200832 0.00047624 0.00174071 0.00158549 0.00614185\n",
      "    0.0061164  0.002808   0.00263295 0.00130137 0.00154655 0.00097924\n",
      "    0.00190906 0.00449859 0.00023517 0.00127227 0.00112042 0.00115631\n",
      "    0.00083291 0.00172885 0.00979246 0.00063394 0.00221637 0.00080528\n",
      "    0.00179456 0.00062244 0.00167155 0.00201794 0.00327342 0.0022587\n",
      "    0.00192219 0.00048976]]\n",
      "\n",
      "  [[0.00515201 0.00188719 0.00038919 0.001632   0.00162534 0.00455954\n",
      "    0.00612311 0.00270673 0.00258954 0.00131976 0.00177859 0.00095283\n",
      "    0.00216429 0.004325   0.00026692 0.00117106 0.00120428 0.00117942\n",
      "    0.00082218 0.00176112 0.00965323 0.00063812 0.00216005 0.00088231\n",
      "    0.00177381 0.00070441 0.00156917 0.00197569 0.0035931  0.00225697\n",
      "    0.00198693 0.00053677]]\n",
      "\n",
      "  [[0.00570532 0.00188042 0.00034008 0.00159383 0.00180635 0.00384427\n",
      "    0.00590129 0.00225786 0.00260033 0.00121631 0.00182489 0.00090007\n",
      "    0.00213081 0.00456266 0.00032662 0.00118453 0.00118029 0.00158085\n",
      "    0.00076862 0.001964   0.00900215 0.00054193 0.00218357 0.00089963\n",
      "    0.0017543  0.00085137 0.00164752 0.00216731 0.00372093 0.00227343\n",
      "    0.00212983 0.00054579]]\n",
      "\n",
      "  [[0.00617641 0.00186188 0.00032597 0.00159101 0.00220901 0.00300016\n",
      "    0.00553009 0.00199071 0.0024941  0.00099935 0.00166346 0.00088808\n",
      "    0.00183676 0.00501395 0.00038222 0.00135823 0.00108733 0.00194854\n",
      "    0.00063814 0.00238551 0.00823913 0.00040201 0.00193637 0.00095177\n",
      "    0.00170635 0.00093477 0.00177687 0.00242021 0.00348895 0.00231485\n",
      "    0.00213989 0.00051697]]\n",
      "\n",
      "  [[0.00581297 0.00181314 0.00028545 0.00164621 0.00250307 0.00237871\n",
      "    0.00523104 0.00187898 0.00233235 0.00087091 0.00149218 0.00099147\n",
      "    0.00161028 0.004935   0.00048192 0.00165177 0.00102175 0.00217787\n",
      "    0.00053423 0.00266896 0.00823892 0.00032882 0.00190404 0.0010285\n",
      "    0.00161525 0.00085379 0.00168192 0.00236176 0.00317744 0.00248053\n",
      "    0.0022028  0.00049188]]]\n",
      "\n",
      "\n",
      " [[[0.00451298 0.00155584 0.00058741 0.00159466 0.00160356 0.0076701\n",
      "    0.00608464 0.00210236 0.00267769 0.00136083 0.00146002 0.00105467\n",
      "    0.00180979 0.00498634 0.00020314 0.00135432 0.00090424 0.00131675\n",
      "    0.0007862  0.00184043 0.01057983 0.00061186 0.00251967 0.00071938\n",
      "    0.0017965  0.00071312 0.00174833 0.00213162 0.00372472 0.00199774\n",
      "    0.00177812 0.00048679]]\n",
      "\n",
      "  [[0.00481056 0.00150847 0.0005033  0.00150571 0.00159467 0.00567772\n",
      "    0.00612839 0.0021407  0.00258155 0.00132379 0.00170765 0.00102241\n",
      "    0.00206283 0.00475426 0.00025845 0.00128795 0.0009728  0.00145646\n",
      "    0.00075899 0.0019322  0.01055664 0.00060395 0.00245551 0.00079589\n",
      "    0.00177576 0.00073744 0.00175587 0.00210946 0.00416211 0.00194761\n",
      "    0.00201444 0.0005253 ]]\n",
      "\n",
      "  [[0.00526087 0.00174163 0.00040808 0.00153886 0.00175314 0.00477493\n",
      "    0.00607439 0.00206257 0.00253235 0.00117545 0.00178464 0.00087817\n",
      "    0.002062   0.00470665 0.00034902 0.00123825 0.00097832 0.00166049\n",
      "    0.00068382 0.00217099 0.00977118 0.00052265 0.00252459 0.00080667\n",
      "    0.00170765 0.00082969 0.00176331 0.00227804 0.0043432  0.00205822\n",
      "    0.00227863 0.00049511]]\n",
      "\n",
      "  [[0.00569221 0.00185992 0.00038088 0.00149354 0.0023021  0.00382452\n",
      "    0.00566448 0.00190692 0.00253737 0.00095173 0.00167234 0.0007903\n",
      "    0.0017697  0.00507579 0.00039293 0.00136787 0.00091608 0.00195109\n",
      "    0.00059645 0.00248942 0.00864276 0.00039493 0.00242353 0.00089024\n",
      "    0.00168368 0.0009188  0.00195116 0.00251009 0.00402822 0.00221428\n",
      "    0.00230907 0.00043698]]\n",
      "\n",
      "  [[0.00528833 0.00177801 0.00033923 0.00145357 0.00266171 0.00292871\n",
      "    0.00527706 0.00173072 0.00244766 0.00083687 0.00149995 0.00080755\n",
      "    0.00162695 0.0051765  0.00040936 0.00163841 0.00097086 0.00199354\n",
      "    0.00052639 0.00268367 0.0081821  0.00031489 0.00232635 0.00099791\n",
      "    0.00169206 0.00087315 0.00193808 0.00249802 0.00362042 0.00240807\n",
      "    0.00231937 0.00040436]]]\n",
      "\n",
      "\n",
      " [[[0.00474186 0.00141167 0.00065407 0.00159582 0.00165008 0.00828796\n",
      "    0.00619766 0.00176178 0.0025561  0.0013001  0.00142352 0.00103912\n",
      "    0.00176606 0.00509569 0.00019938 0.00156827 0.00086114 0.00152285\n",
      "    0.00084299 0.00178523 0.0104978  0.00054453 0.00261901 0.0006331\n",
      "    0.00186566 0.00080104 0.00193684 0.00208808 0.00404476 0.0020276\n",
      "    0.00178384 0.00051887]]\n",
      "\n",
      "  [[0.00481791 0.0013346  0.00056668 0.00150876 0.00164953 0.0066895\n",
      "    0.00627276 0.00173897 0.00247217 0.00123501 0.00159442 0.0010252\n",
      "    0.00192573 0.00501258 0.00025643 0.00151786 0.0009048  0.00170857\n",
      "    0.00079464 0.00190155 0.01051458 0.00047377 0.00282344 0.00068714\n",
      "    0.00186444 0.00075405 0.00190854 0.00209453 0.00445897 0.00192324\n",
      "    0.00202982 0.00052352]]\n",
      "\n",
      "  [[0.00512893 0.00155251 0.00043743 0.00156658 0.00177659 0.00577293\n",
      "    0.00599447 0.00188591 0.00241048 0.00113004 0.00163704 0.00086052\n",
      "    0.00194033 0.00502721 0.00036807 0.00148059 0.00095249 0.00176463\n",
      "    0.00065165 0.00219295 0.00972778 0.00041624 0.00308536 0.00073793\n",
      "    0.00186784 0.00078185 0.00181989 0.00231449 0.00462097 0.00202532\n",
      "    0.00233002 0.00049182]]\n",
      "\n",
      "  [[0.00551918 0.00174026 0.00041053 0.00152743 0.00218589 0.00474591\n",
      "    0.00533863 0.00187044 0.00247622 0.00097835 0.00151558 0.00077306\n",
      "    0.00178212 0.00522975 0.00040208 0.00156631 0.0009158  0.00197645\n",
      "    0.00054348 0.00242561 0.00862281 0.00034693 0.00295804 0.00082962\n",
      "    0.00185363 0.00085099 0.00195523 0.00253826 0.00431287 0.00230208\n",
      "    0.00241656 0.00046061]]\n",
      "\n",
      "  [[0.00521667 0.00171237 0.00040468 0.00143956 0.00261229 0.00379677\n",
      "    0.0051242  0.00169886 0.00242451 0.00090512 0.00135091 0.00079909\n",
      "    0.00174759 0.00519953 0.00037637 0.00169303 0.00101054 0.00205135\n",
      "    0.0004845  0.00250228 0.00812777 0.0002963  0.00287504 0.00090215\n",
      "    0.00185389 0.0008035  0.00198456 0.00247969 0.00376837 0.00244429\n",
      "    0.00239921 0.00044827]]]]\n",
      "[-8.10631942e-03  1.02143007e-02 -8.51328910e-03 -9.33932703e-04\n",
      "  6.71274633e-03  1.06082866e-02 -1.62808783e-02 -8.75356821e-03\n",
      "  4.10851136e-03  9.89296178e-03  7.00556915e-03 -1.20906808e-02\n",
      "  5.68380692e-03  1.45943503e-02  1.02078987e-02  4.49724430e-03\n",
      " -2.01402939e-02 -9.59100847e-03 -1.27900453e-02 -9.93004470e-04\n",
      " -6.66409822e-03 -1.39783845e-03 -9.52494800e-03 -5.40041713e-04\n",
      " -1.62560896e-02 -3.20258312e-03  7.52240490e-03 -6.83470059e-03\n",
      " -2.99112038e-03 -1.00703027e-02  4.22554343e-03 -2.91390388e-03\n",
      "  4.93538474e-03 -8.26779432e-03  4.93742053e-03  1.13197342e-02\n",
      " -9.49906676e-03  4.61217014e-03  9.57795021e-03 -7.98414194e-03\n",
      " -1.04542900e-02  4.54505720e-03 -1.59370791e-02  3.28107780e-03\n",
      "  6.05011616e-03 -8.07008964e-03 -1.33767620e-03 -2.33675403e-03\n",
      " -2.00833382e-02  8.84716366e-03 -2.07984829e-03  2.87800749e-04\n",
      "  9.03800806e-03 -2.67600996e-03 -1.81401287e-03  1.26279882e-03\n",
      "  4.20117378e-03  1.48174489e-03  1.89647210e-03  3.51396936e-03\n",
      "  9.88627348e-03 -3.84811865e-03 -1.12850822e-02  9.83618393e-03\n",
      "  1.58372214e-02 -6.92092655e-03 -1.04466806e-03 -6.21506549e-03\n",
      "  5.33421094e-03 -4.22726844e-03 -6.61669601e-04 -1.01010306e-02\n",
      " -1.40937685e-03 -1.67557036e-02 -7.48021417e-03  6.10541873e-04\n",
      "  5.55570164e-04 -3.05105403e-03  7.32286103e-03  5.37713068e-03\n",
      " -3.58959328e-03 -1.10912683e-02  6.00043131e-03  4.49255388e-04\n",
      "  9.68608218e-03 -1.65320847e-02  1.06886459e-02 -6.74313880e-03\n",
      " -5.83203158e-03  3.51419594e-03  9.40750596e-03  4.25718475e-03\n",
      " -7.03648752e-03 -1.37243075e-03  3.20554243e-03 -1.14072461e-03\n",
      "  1.25184077e-02  2.76522008e-03 -3.31309918e-05 -1.14359973e-02\n",
      "  5.78096965e-03  4.32767484e-04  1.70544830e-03 -4.77314578e-03\n",
      " -9.22108583e-03  1.23633676e-03 -2.09910487e-03 -1.14931979e-03\n",
      " -1.55706312e-03 -3.64638881e-03 -6.54283474e-03  9.13818955e-04\n",
      " -2.49374067e-03  5.62739066e-03 -1.60495585e-02  9.52295984e-03\n",
      " -1.40142989e-02 -1.06274596e-02  6.83102021e-03 -1.04434809e-02\n",
      "  6.42273537e-03 -6.83268420e-03 -6.11313317e-03  3.36291444e-03\n",
      "  6.35378708e-03  1.14705647e-03  2.33438391e-03  1.14654981e-02\n",
      "  7.07049733e-03  3.04208362e-03  1.43704183e-02 -2.36464167e-03\n",
      "  9.06622964e-03 -4.60482796e-03  1.28611858e-02 -1.40239199e-02\n",
      "  6.87714404e-03  4.33184314e-03 -6.89580559e-04 -5.34848648e-03\n",
      "  2.32038119e-03  1.38195010e-03 -1.49921821e-02 -5.28722763e-03\n",
      " -4.75053082e-03  1.31177376e-02  1.52130531e-03  1.59965849e-02\n",
      " -2.14704789e-04 -1.23761916e-02 -8.92757703e-03  1.19214524e-02\n",
      "  1.69745962e-03 -2.48167744e-03  4.28345812e-03 -1.72664581e-03\n",
      "  7.85252768e-04 -7.44086781e-03 -3.86485792e-03 -4.06152596e-03\n",
      " -1.07272242e-02 -5.22713887e-03 -1.41439211e-03 -7.39646000e-03\n",
      "  5.02788375e-03 -1.44934936e-02  2.45234817e-03 -1.21145974e-02\n",
      "  1.20550784e-03  1.94776221e-02 -9.41159151e-04 -2.55491406e-02\n",
      "  6.46753317e-03 -2.09081557e-03  2.12767722e-02  7.30322166e-03\n",
      " -1.94775142e-02  4.17471167e-03  4.52820213e-03  7.74919275e-03\n",
      " -1.54505892e-02  1.28259904e-02 -1.10616202e-02 -1.10513008e-02\n",
      "  1.02348091e-02 -1.38471623e-02  1.24182650e-02  5.84532370e-03\n",
      "  1.04094685e-02 -1.48988783e-02  2.63097067e-03 -1.32203162e-02\n",
      "  3.80221747e-03 -5.61605103e-03 -4.19808563e-03 -1.99319571e-03\n",
      " -5.61228413e-03  6.75069050e-03  2.73364858e-03 -1.05131911e-02\n",
      "  1.78327023e-02 -1.68272758e-03  2.59878371e-03  1.72712153e-03\n",
      " -3.83029752e-03  6.02669893e-04  4.31961292e-03 -1.68642085e-03\n",
      "  3.63515057e-03 -3.25313223e-03 -4.36105306e-03 -9.10541062e-03\n",
      " -9.26689226e-03  1.17453507e-03 -1.46622369e-02  1.83444250e-03\n",
      " -4.52323302e-03  4.01385200e-03  4.26754709e-03 -3.44394305e-03\n",
      " -2.46441442e-03  8.80831214e-03 -7.62285036e-03 -7.77697482e-03\n",
      "  9.05957916e-03  1.83285987e-03  1.91162466e-05 -1.33402299e-02\n",
      " -4.73799123e-03 -4.26273205e-03 -1.05143554e-02 -1.07716970e-03\n",
      " -2.48690094e-03  7.12511771e-03  4.47336101e-03 -9.36012572e-03\n",
      " -8.64823972e-03 -1.52419297e-02  1.43786005e-02 -3.05409068e-03\n",
      " -7.05318525e-03 -1.13905338e-03  8.18083089e-03 -9.78427105e-03\n",
      " -9.25405521e-04  8.46030131e-03  2.10178155e-03 -5.69163341e-04\n",
      "  2.03386379e-05 -5.46625517e-03 -5.27575285e-03 -7.23456107e-03\n",
      "  8.11674401e-03  1.00617828e-02  8.83425514e-03 -9.93731762e-03\n",
      "  3.83372345e-03  7.89724198e-03 -1.23941060e-02 -3.30226636e-03\n",
      " -1.33896670e-02  4.90572428e-03  5.92043022e-03  2.82546213e-03\n",
      " -4.86941173e-03 -7.54219708e-03  1.91542717e-02  1.88209128e-02\n",
      "  1.84288200e-02 -3.55645594e-03  9.85740958e-04 -9.87632431e-03\n",
      "  7.30132049e-03  8.06384890e-04  6.15216686e-03 -2.37969157e-03\n",
      " -1.57027312e-03 -1.98983365e-02 -7.65442743e-03 -7.08768449e-03\n",
      " -1.60456384e-02 -1.85180810e-02 -2.10957942e-02  5.01883838e-03\n",
      "  3.79383132e-03 -2.99064112e-03  3.96086172e-03 -9.09848749e-04\n",
      "  2.11724044e-03 -6.56059149e-03  5.63063024e-03  1.49000159e-02\n",
      " -7.34659197e-03 -1.04860321e-02  3.26965878e-03 -7.84094291e-03\n",
      "  2.69098216e-03 -1.19807180e-02 -2.04462680e-03  3.20412124e-03\n",
      " -1.29428824e-02 -9.72384958e-03 -1.57213026e-03  3.15526989e-03\n",
      "  8.12349975e-03  1.16464953e-04  7.57903894e-04  1.05833075e-02\n",
      "  9.95294441e-04 -5.42080354e-04  6.53873568e-03 -1.99457126e-02\n",
      "  1.61627172e-03  1.73709971e-02 -3.77866591e-03  1.19462394e-02\n",
      " -2.14515037e-02 -2.38687469e-03  1.35533295e-03  6.07349530e-03\n",
      " -1.18127724e-04  1.21362318e-03  2.29820101e-03  1.17558777e-04\n",
      " -3.84957965e-03 -6.56710400e-03 -2.62318662e-03 -3.74253090e-03\n",
      " -1.13303859e-02 -1.90009260e-02 -2.12193143e-02 -2.04224314e-02\n",
      "  2.71276200e-03 -1.37698118e-02 -1.00824553e-02  7.33022091e-03\n",
      "  3.27443755e-03  1.21326910e-02  5.96421689e-04  7.55244566e-03\n",
      "  1.87599590e-02 -2.08377874e-03  1.26950337e-02 -7.26726079e-03\n",
      " -1.69079657e-03  1.66024416e-02  3.02374246e-03  5.17495350e-03\n",
      " -4.87726409e-03 -1.18132697e-03  5.00384650e-03 -4.55001049e-03\n",
      " -1.05811745e-02 -1.52929495e-03  4.71862403e-03  7.59238505e-03\n",
      " -6.50131873e-03 -6.77111670e-03  3.01015842e-04 -4.42127120e-03\n",
      "  1.09031485e-02 -1.58153208e-02  3.44542562e-03 -3.95478686e-03\n",
      " -1.46526683e-02 -5.48649415e-03 -1.21633208e-02  8.15350197e-03\n",
      "  1.74205757e-02  9.91887303e-03  8.60279766e-03  3.66471763e-03\n",
      "  3.30009605e-03 -5.99107738e-03 -1.70900803e-02  4.89298216e-03\n",
      " -5.90030148e-03  9.81703359e-03 -9.79179484e-03  2.26135441e-03\n",
      " -9.67343760e-03 -4.47034836e-03  4.21712461e-03 -4.03851814e-03]\n",
      "[-1.02349685e-05 -1.06318744e-05  2.37764762e-06 -1.01301575e-05\n",
      "  1.27052176e-05  9.13325472e-06  1.67763987e-07 -2.13448476e-05\n",
      "  2.82810075e-05  2.23004279e-05  3.04138197e-05 -1.72830534e-05\n",
      " -8.27706069e-07  1.82691396e-05  2.42195012e-05  1.65438690e-05\n",
      " -2.27033394e-05 -1.30441706e-05 -1.83308795e-05  1.08231078e-05\n",
      "  2.38149307e-06 -7.58307702e-06 -1.31177248e-05 -2.05644855e-05\n",
      " -3.08339682e-05 -2.90509808e-05  3.83400713e-06  1.51029221e-05\n",
      "  2.53786040e-06 -5.79776586e-06  1.85584504e-05  8.34563502e-06\n",
      " -7.22160107e-06 -4.42971859e-05 -2.38561080e-05 -2.06550700e-05\n",
      " -3.30956718e-05  1.82284427e-05 -1.11272933e-05  5.21286542e-06\n",
      "  2.43559320e-05 -8.41844989e-06 -6.81318462e-06 -2.07579415e-06\n",
      " -4.72862435e-06 -8.67600865e-06  2.48463509e-05 -1.89190325e-05\n",
      "  9.76525321e-08  1.11157306e-05 -1.54620224e-05  4.94620559e-06\n",
      "  3.34375483e-05  7.95632689e-06 -2.82158776e-05 -3.92610329e-06\n",
      "  4.88291397e-06 -8.96849947e-06  1.39232809e-05  1.05180233e-05\n",
      " -1.05932237e-05  1.85609738e-05 -2.80677132e-05 -9.65211055e-06\n",
      "  1.49642130e-05  5.84249461e-07  1.76691432e-05 -1.93961007e-05\n",
      " -3.47163519e-07 -3.46446915e-05 -1.72724356e-05  1.53267488e-06\n",
      "  1.27163191e-06  1.12650485e-05  9.22390614e-06 -1.00354946e-05\n",
      "  7.56341246e-06 -1.20574937e-05  8.23719397e-06 -6.97503949e-07\n",
      "  1.08473483e-05  1.78829251e-06  5.50008250e-06  3.52865148e-05\n",
      "  4.99019059e-05 -2.35388715e-05 -1.74444737e-05  2.65042718e-05\n",
      " -7.18050339e-06  2.77619853e-05  1.49705624e-05  9.82707408e-07\n",
      "  8.17226887e-06 -1.74533160e-05 -1.01237739e-05 -1.94572411e-05\n",
      "  8.99606837e-06  3.02868795e-06  6.48904565e-06 -1.56467629e-05\n",
      "  2.19274148e-05  1.62973060e-05  3.32316767e-05 -2.16428326e-05\n",
      " -2.42556992e-05  1.99149553e-05 -3.23829650e-05 -2.22379586e-05\n",
      " -2.25188295e-05 -3.08050289e-05 -2.73373156e-05  2.16116659e-05\n",
      "  1.79380261e-05 -3.90124475e-06 -9.13296234e-06  2.28932862e-05\n",
      " -1.51524461e-05 -1.58180498e-05  2.58863887e-05 -1.51392471e-05\n",
      "  3.82556245e-06 -1.61450960e-05 -7.26745206e-06 -1.12681147e-05\n",
      " -1.50009207e-05 -2.39319778e-06  2.73257979e-05 -5.02907131e-06\n",
      "  1.19904272e-05 -2.97947177e-05  2.24796787e-05 -1.51889559e-05\n",
      "  2.69324007e-05  1.10152936e-05  7.00012919e-06  5.42500884e-06\n",
      " -1.53449105e-05  1.66753084e-05  1.24799881e-05  8.61664899e-06\n",
      " -2.85930414e-05  1.47545607e-05 -2.82271448e-05 -2.16718637e-05\n",
      "  1.79255645e-06 -7.41293358e-06  1.25667141e-05 -2.19063190e-06\n",
      "  1.52464151e-05 -2.13492006e-05 -3.15366974e-05  7.39743430e-06\n",
      " -1.22783909e-05 -1.78019137e-05 -9.88556589e-06  5.77564504e-06\n",
      " -6.33143847e-06 -2.33499737e-05  1.47557581e-05  8.29864074e-06\n",
      " -2.94894845e-05  2.49868589e-05  1.86981421e-06 -6.91990377e-06\n",
      "  9.24678827e-06 -9.22569374e-07  3.99318851e-05 -3.28661745e-05\n",
      "  2.47468896e-05  2.46245604e-05 -2.98036209e-05 -7.45104319e-06\n",
      " -2.31310868e-05  2.90792744e-05 -6.13924592e-07 -5.28273503e-06\n",
      "  5.25981121e-06  3.23105184e-05  4.40151896e-06 -8.51377618e-06\n",
      " -1.29555412e-05  2.51830635e-05 -1.05959991e-05 -4.71798448e-05\n",
      " -8.52447243e-06 -2.31551113e-05 -2.21740866e-06  6.71289662e-06\n",
      "  1.87440868e-05  5.08623886e-06  1.23489189e-05  1.82866814e-06\n",
      " -2.21016092e-06  5.76646764e-06  1.77493262e-05  1.26325042e-05\n",
      "  2.25823995e-05  1.55903732e-05 -1.50868255e-06  1.31162459e-05\n",
      "  3.09428853e-05 -2.80524613e-05  4.31146766e-06  1.86158032e-05\n",
      " -3.00046740e-05  6.30857747e-06 -5.25309050e-07  1.99749321e-05\n",
      "  2.52255693e-05 -1.17950706e-05 -2.58950563e-05  9.34044892e-06\n",
      " -3.08908588e-06  7.92006688e-07 -2.39057620e-05  1.40419292e-05\n",
      " -1.10614020e-05  1.61910775e-05  5.88589879e-06  3.03717238e-06\n",
      " -1.54112489e-05 -4.25919487e-06 -9.13554393e-06 -2.05466655e-05\n",
      " -1.19506202e-05  5.15049426e-06 -2.49383290e-05 -1.37340471e-05\n",
      " -2.01419614e-05 -1.11918260e-05 -2.62567740e-05  4.41994818e-05\n",
      " -1.87832773e-05  8.83448528e-09 -6.85430527e-06 -2.53164165e-06\n",
      " -1.44605561e-05 -1.72526642e-05  2.17520835e-06 -2.45375621e-06\n",
      "  8.90784166e-06  8.14629128e-06  8.31711639e-06 -1.68726619e-05\n",
      " -2.34769779e-06  1.33319851e-05  1.13723010e-05 -3.75015143e-06\n",
      "  2.75546844e-05 -1.60296893e-05  4.31331377e-06  1.12328070e-05\n",
      "  1.67686741e-05  2.37739489e-05  1.88384755e-05 -1.09841727e-05\n",
      "  2.96992070e-05 -5.01291680e-06 -1.44204761e-05 -1.44241661e-05\n",
      " -9.25698977e-06  2.56527598e-05  5.63834843e-05 -1.04115432e-05\n",
      " -3.33712631e-06  3.36669178e-06 -5.32051451e-06  1.62826913e-05\n",
      "  3.83704198e-05  3.11116180e-07  1.80549623e-05  2.88260567e-05\n",
      " -4.48060056e-07 -1.43854160e-05  1.05995585e-05  5.06732863e-06\n",
      "  2.24330952e-06 -6.92906057e-06 -1.26415117e-05  1.29598522e-05\n",
      " -2.01367789e-05 -2.59923480e-05  3.78084637e-06  1.98054557e-05\n",
      "  1.96263868e-05 -1.70609967e-05 -3.46976237e-05  4.79458782e-06\n",
      "  2.21933849e-05  8.72034611e-06  1.76889501e-05  2.35091817e-05\n",
      " -2.28167638e-05 -4.45468061e-05 -3.46783665e-06  1.61488069e-05\n",
      " -1.05000191e-05  1.41739584e-06 -7.31807798e-06 -5.13709262e-06\n",
      " -1.51915543e-05 -1.54144236e-05 -1.36706890e-06 -2.08323674e-06\n",
      "  3.94956983e-05  2.09068736e-05 -7.05857261e-06  1.27751317e-05\n",
      "  2.01113928e-06  1.29960933e-05  3.54346683e-05  9.26374621e-06\n",
      " -1.30365546e-05  2.77473782e-05  9.14204207e-06 -4.01729842e-06\n",
      " -2.88497822e-05  2.52184449e-05  2.69222160e-06  9.06832150e-06\n",
      "  1.33745224e-06 -3.26432094e-06  1.29849604e-05  1.30500961e-06\n",
      "  2.04207264e-05 -2.05431317e-05 -2.18131972e-05 -1.00043714e-05\n",
      " -1.67875433e-06 -2.12745056e-05  4.36334652e-06 -3.15048889e-05\n",
      "  1.49204303e-06 -2.48666843e-05 -8.24422421e-06  1.01089800e-05\n",
      " -1.47367050e-05  9.69831536e-06  2.53046021e-05 -1.34931527e-05\n",
      " -9.22439783e-07  1.17668351e-05 -3.88617064e-06 -3.06209652e-06\n",
      "  2.50760148e-05  2.42660821e-05  1.14054656e-05  2.82451670e-05\n",
      " -2.56780897e-05  1.04771623e-05 -1.67332693e-05  2.41354318e-05\n",
      " -5.64684598e-06  1.25514140e-05  1.53482725e-05  3.53245522e-05\n",
      "  1.23034977e-05 -7.35563705e-06 -7.13232302e-06  8.24827558e-06\n",
      "  1.90555830e-05 -6.57452318e-06  2.85977117e-05  6.63622760e-06\n",
      " -1.71470936e-05 -1.33558374e-05 -2.86015109e-06  1.39485111e-05\n",
      " -1.07780801e-05  1.37765388e-05 -2.39915619e-05 -2.94286279e-05\n",
      " -3.54176104e-06  6.59882668e-06 -1.66088436e-05  1.17474347e-05\n",
      " -3.24680225e-06 -3.02506339e-07 -1.63478231e-05 -2.36350738e-06\n",
      "  1.12282062e-05  1.17543813e-05 -6.33982089e-06  1.15366958e-05]\n",
      "[4.73179690e-06 6.30061243e-06 4.03893907e-06 6.67130274e-06\n",
      " 7.60555805e-06 2.95346772e-05 5.61499597e-06 5.38656177e-06\n",
      " 8.71506108e-06 5.83024286e-06 6.10410020e-06 1.04738174e-05\n",
      " 3.72720320e-06 5.53659301e-06 8.59162187e-06 1.85147089e-05\n",
      " 8.04324793e-06 1.43756064e-05 7.70685279e-06 7.78830181e-06\n",
      " 9.15091487e-06 7.72700252e-06 1.10149120e-05 7.49942179e-06\n",
      " 3.17902851e-06 1.29116836e-05 4.50139876e-06 1.33123527e-05\n",
      " 4.78934677e-06 1.66175576e-05 3.26235081e-06 4.79535366e-06\n",
      " 7.10618830e-06 4.79991517e-06 5.09399875e-06 8.02038984e-06\n",
      " 9.13183368e-06 2.84495913e-05 2.85867225e-06 6.87862771e-06\n",
      " 3.66789428e-06 8.36965437e-06 8.78191365e-06 3.55956668e-06\n",
      " 3.04334129e-06 1.91612413e-05 1.03043742e-05 4.62321995e-06\n",
      " 1.72769809e-05 1.66839189e-05 1.58250839e-05 1.45981831e-05\n",
      " 5.19279060e-06 3.41151173e-06 3.97933697e-06 8.38578483e-06\n",
      " 1.54361041e-05 1.33135836e-05 7.76564114e-06 6.33142669e-06\n",
      " 1.04636815e-05 6.05133127e-06 6.88474209e-06 6.19576163e-06\n",
      " 4.59385927e-06 1.78661207e-05 8.31676917e-06 7.20108605e-06\n",
      " 4.52073073e-06 8.69537897e-06 1.04438990e-05 4.88357699e-06\n",
      " 3.12108658e-06 4.85068665e-06 6.52869680e-06 2.66651683e-06\n",
      " 7.02733816e-06 2.28631253e-06 6.71613878e-06 1.00881008e-05\n",
      " 6.03304503e-06 3.93339046e-06 9.46224521e-06 6.04301775e-06\n",
      " 1.14426777e-05 4.76033858e-06 1.33186512e-05 1.67048254e-05\n",
      " 1.21913580e-05 1.53208873e-05 1.01029416e-05 4.58922412e-06\n",
      " 7.08380566e-06 3.40208643e-06 4.11571405e-06 3.55760955e-05\n",
      " 6.64019959e-06 7.42653391e-06 4.78111447e-06 3.38345312e-06\n",
      " 2.11491178e-05 7.34788848e-06 6.82176831e-06 6.68122096e-06\n",
      " 1.24175799e-05 1.25497127e-05 2.01039140e-05 9.23073724e-06\n",
      " 2.15303984e-05 2.23584203e-05 2.10382900e-05 1.13257715e-05\n",
      " 9.46149285e-06 2.48101277e-06 7.78372352e-06 3.82352615e-06\n",
      " 4.97316798e-06 1.90286639e-05 5.76125994e-06 5.47156554e-06\n",
      " 4.99958401e-06 5.14153658e-06 3.37531264e-06 5.99889904e-06\n",
      " 7.70528298e-06 1.13206781e-05 1.03003302e-05 5.02406146e-06\n",
      " 9.29375088e-06 1.07947486e-05 1.38516817e-05 1.32852793e-05\n",
      " 1.51090537e-05 3.73621290e-06 4.54860268e-06 4.79062718e-06\n",
      " 1.10089215e-05 1.10627306e-05 4.42543822e-06 4.62880905e-06\n",
      " 7.11268518e-06 1.48507593e-06 1.85391540e-05 3.19707332e-06\n",
      " 9.24420731e-06 3.58679877e-06 5.53756079e-06 4.75938670e-06\n",
      " 1.84943061e-05 5.61672723e-06 1.56666817e-05 8.03549922e-06\n",
      " 5.56750217e-06 1.64537259e-05 4.32623104e-06 2.53461976e-06\n",
      " 8.03613711e-06 9.31779705e-06 6.36893063e-06 8.51613250e-06\n",
      " 7.53887404e-06 1.28540538e-05 7.61132827e-06 6.11538271e-06\n",
      " 9.92840972e-06 6.98650780e-06 7.94406876e-06 5.43397529e-06\n",
      " 2.27428447e-05 1.08088109e-05 5.47449327e-06 1.95346730e-05\n",
      " 1.20677111e-05 6.77280402e-06 8.22028989e-06 1.04331563e-05\n",
      " 1.55254481e-05 7.81497693e-06 1.90041547e-05 3.03214033e-05\n",
      " 1.18862306e-05 3.74601793e-06 1.04010129e-05 1.80460711e-05\n",
      " 2.36440373e-06 1.73582725e-05 8.10580947e-06 1.16376553e-05\n",
      " 3.38875321e-06 3.07868821e-06 9.40888126e-06 5.83608016e-06\n",
      " 9.57032617e-06 3.67979218e-06 3.11038245e-06 1.52773516e-05\n",
      " 5.71505739e-06 1.31433123e-05 2.18276663e-05 8.98557777e-06\n",
      " 1.35438247e-05 2.73045859e-05 1.91771903e-05 3.93418941e-06\n",
      " 1.04653414e-05 1.73842769e-05 6.62148946e-06 1.84469152e-05\n",
      " 1.03010691e-05 8.94821029e-06 2.73851466e-05 3.50886625e-06\n",
      " 1.13622933e-05 5.95809004e-06 1.44129372e-05 3.40256730e-06\n",
      " 1.14549780e-05 4.44415746e-06 2.30779789e-06 1.16361009e-05\n",
      " 1.25358956e-05 8.74664150e-06 1.05354985e-05 1.05878640e-05\n",
      " 1.12047386e-05 7.00336209e-06 9.29591680e-06 5.43114367e-06\n",
      " 1.86137902e-05 2.56578842e-06 4.59782175e-06 8.49047756e-06\n",
      " 7.49376776e-06 3.22707840e-06 1.90386261e-05 2.65732377e-06\n",
      " 2.71523075e-06 4.75376526e-06 1.15995963e-05 7.86969386e-06\n",
      " 5.29428318e-06 3.03700339e-06 7.73813550e-06 5.37173027e-06\n",
      " 4.93632530e-06 4.03210040e-06 6.64305057e-06 3.54898364e-06\n",
      " 2.02088502e-05 2.77511895e-05 6.64424634e-06 1.69863811e-05\n",
      " 9.69243240e-06 8.56510098e-06 6.11255617e-06 1.20972050e-05\n",
      " 5.27129740e-06 3.90494866e-06 9.75360691e-06 1.44778062e-05\n",
      " 6.68479995e-06 1.85684740e-05 1.20118992e-05 3.70599106e-06\n",
      " 1.07126270e-05 1.17812936e-05 4.37128384e-06 4.36614733e-06\n",
      " 1.06521510e-05 2.38481183e-05 2.34171873e-06 5.57009301e-06\n",
      " 7.97622854e-06 6.87904509e-06 1.10850422e-05 1.03349938e-05\n",
      " 6.33079941e-06 7.50731773e-06 8.07131745e-06 7.04973842e-06\n",
      " 7.19350643e-06 1.61304781e-05 8.00086953e-06 3.03589515e-06\n",
      " 6.16878047e-06 5.46505861e-06 1.54291192e-05 1.39367964e-05\n",
      " 8.23858669e-06 2.49553695e-05 4.26246255e-06 1.82799644e-05\n",
      " 1.66534520e-05 9.24553030e-06 1.71612532e-05 5.27793086e-06\n",
      " 1.85277974e-05 7.11423177e-06 1.78034714e-05 7.53779559e-06\n",
      " 7.88597875e-06 8.02845878e-06 1.02878177e-05 2.09032274e-05\n",
      " 1.35559270e-05 6.18630286e-06 1.27830409e-05 9.46110097e-06\n",
      " 1.04788963e-05 9.60802505e-06 1.10468895e-05 6.70495206e-06\n",
      " 5.39321583e-06 4.69643949e-06 3.97955671e-05 6.17203766e-06\n",
      " 1.42631354e-05 5.12841380e-06 2.18322977e-06 6.18916272e-06\n",
      " 1.80037152e-05 1.27099361e-05 6.86880228e-06 5.42683630e-06\n",
      " 4.63503259e-06 1.19081167e-05 5.49501532e-06 1.17891310e-05\n",
      " 5.20919066e-06 1.21768822e-05 5.22027511e-06 1.10272911e-05\n",
      " 7.33416696e-06 8.91086199e-06 4.61646307e-06 6.14042521e-06\n",
      " 9.67267233e-06 1.47131962e-05 1.78836091e-05 8.48637804e-06\n",
      " 6.89883447e-06 2.48264213e-05 1.39731486e-05 3.22363711e-06\n",
      " 4.16191867e-06 8.62808223e-06 5.06416710e-06 1.05552363e-05\n",
      " 1.43884459e-05 4.37958590e-06 5.31682619e-06 7.38165280e-06\n",
      " 4.45258174e-06 6.95694234e-06 1.26396279e-05 1.01877454e-05\n",
      " 2.70144007e-06 3.95206569e-06 5.78496035e-06 6.82629112e-06\n",
      " 1.53227148e-05 6.17272340e-06 1.95458927e-05 7.24450783e-06\n",
      " 8.05094945e-06 3.38064920e-05 4.04541161e-06 4.91233059e-06\n",
      " 2.64196226e-06 3.28578416e-06 6.49603349e-06 4.27202919e-06\n",
      " 1.03438728e-05 4.90349505e-06 3.90703380e-06 6.48834380e-06\n",
      " 1.70356564e-05 7.54591077e-06 7.31037501e-06 1.75230625e-05\n",
      " 7.65963655e-06 1.06888167e-05 5.69365601e-06 5.98258728e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03897516  0.0213458  -0.03969271 ... -0.01855679 -0.02201183\n",
      "   0.01893385]\n",
      " [-0.00184503 -0.0117447  -0.02638443 ...  0.02200966 -0.0240982\n",
      "  -0.0069953 ]\n",
      " [ 0.00751587 -0.01771944  0.015354   ...  0.01677909  0.00414758\n",
      "   0.01135595]\n",
      " ...\n",
      " [ 0.00968331 -0.01898595 -0.03369742 ...  0.00131062 -0.01359075\n",
      "  -0.02741245]\n",
      " [-0.00945907  0.02294301  0.00119755 ...  0.02577015 -0.0083414\n",
      "  -0.03309178]\n",
      " [ 0.00537963 -0.01029532  0.01491789 ... -0.0130411  -0.01476128\n",
      "  -0.01641878]]\n",
      "[[-1.92479328e-06 -4.87560126e-07  1.05028753e-06 ...  1.24550859e-06\n",
      "  -1.16284449e-06  1.01766435e-06]\n",
      " [-1.59301744e-07 -1.57910108e-07  2.04692982e-07 ...  1.40906752e-08\n",
      "  -4.73020285e-07  2.44550954e-07]\n",
      " [ 1.20218342e-07 -1.17997317e-07 -7.72562785e-08 ... -8.82302987e-08\n",
      "   1.22376171e-08  8.98501778e-08]\n",
      " ...\n",
      " [ 1.80372508e-06 -1.48718080e-06 -5.58272160e-07 ...  3.10143944e-07\n",
      "   1.12972166e-08  5.17969219e-08]\n",
      " [-6.52383630e-07 -1.03546028e-06  5.45899310e-07 ...  1.22541052e-06\n",
      "  -3.16018339e-07  5.68472468e-07]\n",
      " [ 1.82980916e-07 -7.28153704e-08 -6.96649170e-08 ...  1.44271038e-08\n",
      "   4.29670395e-08 -8.98314148e-08]]\n",
      "[[8.58260691e-08 1.33878023e-07 7.44693582e-08 ... 2.56611731e-07\n",
      "  1.72016661e-07 1.51716399e-07]\n",
      " [4.67102783e-09 5.97884633e-09 3.73702589e-09 ... 1.12199299e-08\n",
      "  1.07874833e-08 7.14622263e-09]\n",
      " [1.86100966e-10 2.55801547e-10 1.18853254e-10 ... 3.59321247e-10\n",
      "  8.02046036e-10 5.80284954e-10]\n",
      " ...\n",
      " [3.02051420e-08 6.13815274e-08 3.46898882e-08 ... 1.31140975e-07\n",
      "  9.66513748e-08 7.89350543e-08]\n",
      " [5.78702479e-09 1.38717673e-08 7.95687386e-09 ... 3.24086367e-08\n",
      "  2.35859421e-08 2.13045775e-08]\n",
      " [5.39462204e-10 3.22748321e-10 1.70006859e-10 ... 8.09477897e-10\n",
      "  1.38347666e-09 6.37185442e-10]]\n",
      "[ 1.43950748e-02  1.35297703e-02 -5.90628193e-03  8.24438952e-03\n",
      "  1.38343598e-03 -2.41654339e-03 -2.65389827e-03  7.55391808e-03\n",
      "  3.78150583e-03  1.03452790e-03 -2.62004470e-03  3.06571970e-03\n",
      "  1.90516134e-03  7.17412094e-03  4.98766580e-03  8.34407081e-03\n",
      " -4.47237411e-03 -6.80257211e-03  1.00734054e-02 -3.15204528e-03\n",
      "  1.98986476e-03  1.60830971e-02 -8.66358447e-03 -1.18830542e-05\n",
      " -3.05016006e-03  3.21264600e-04 -2.34088211e-03 -1.66683002e-03\n",
      "  9.23259180e-04  1.78650653e-02  7.23699543e-03  4.30030886e-03\n",
      " -1.38738894e-02 -6.59322892e-03 -5.34301656e-03 -2.45582781e-03\n",
      "  4.13911152e-04 -4.09123995e-03  4.80375610e-03  2.78443030e-04\n",
      " -1.52930414e-02  9.72770248e-03  2.86649582e-03  8.50065622e-04\n",
      " -1.14432890e-04  3.34010669e-03 -2.51829939e-03  1.75699210e-04\n",
      " -7.61872204e-03  2.71172455e-03  6.81350166e-03  1.35074216e-02\n",
      " -2.13396857e-04 -1.14491451e-03  3.63509786e-03 -1.65288854e-03\n",
      "  1.32024750e-02  7.44381127e-03  6.25257440e-04 -6.68655841e-03\n",
      "  2.00698497e-03  1.91815281e-03  1.15824665e-02  2.61515927e-03\n",
      "  1.28332125e-02 -2.73662776e-03 -5.59880934e-03  5.78270594e-03\n",
      " -7.41904777e-03  5.31440201e-03  7.48865008e-03  2.20249505e-04\n",
      " -1.07392468e-02  1.58942660e-02  3.08062367e-03  9.30019460e-04\n",
      " -9.20177281e-03  5.18751091e-03 -1.26830783e-02 -4.35425524e-03\n",
      " -4.55546661e-03 -5.49771013e-03  5.50173003e-03 -4.12128321e-03\n",
      "  3.57370297e-03  2.56289995e-03 -1.33434396e-02 -5.44451005e-03\n",
      " -1.36565491e-03 -1.81051081e-03 -9.34264400e-03 -2.93874016e-03\n",
      " -6.39816366e-03 -2.79299362e-03 -3.99457908e-03  4.41918635e-03\n",
      "  1.44429134e-02  3.35768425e-03 -2.55672108e-03 -7.60285836e-03\n",
      "  1.92025428e-02  1.03945458e-03  6.90935823e-04  3.97416633e-03\n",
      "  9.59532827e-03 -3.19818551e-03 -1.18099014e-02 -5.39503109e-03\n",
      "  4.41223225e-03  5.91628543e-03 -3.98226218e-03 -1.13568972e-02\n",
      "  5.04205308e-03  1.22826399e-03 -9.14451235e-03 -1.07563300e-02\n",
      "  8.44127197e-03  3.55429384e-03  1.36236420e-02 -7.83664643e-03\n",
      " -3.74951902e-03  4.67962494e-03 -3.60687507e-03  7.16190303e-03\n",
      "  7.52241427e-03  1.12512059e-02  9.40679185e-04 -1.55681314e-03\n",
      " -6.03806929e-04 -7.71389497e-03 -5.02231365e-03  1.52793591e-02\n",
      " -2.69252938e-03  7.44761810e-03  1.62058685e-03 -3.48126046e-03\n",
      " -2.92092497e-03  8.92315643e-03  3.20326212e-03  2.68425428e-04\n",
      " -1.61670758e-02 -2.53076717e-03 -1.39513153e-03  1.03096394e-02\n",
      " -3.57023419e-03  9.87846722e-03 -5.43785783e-04 -1.64096938e-02\n",
      "  1.42489787e-03 -1.13890661e-02  2.99136904e-03 -2.83677989e-03\n",
      "  6.96785030e-03  5.52309824e-03 -3.40710760e-03  2.92358058e-03\n",
      "  9.55993401e-03  4.29971475e-03  1.38914103e-03 -7.19117241e-03\n",
      "  3.11659032e-03 -5.00833660e-03  8.18262888e-04  1.97411550e-03\n",
      "  5.72247607e-03 -2.05292344e-03  1.01556096e-02 -1.01712799e-02\n",
      "  1.07443418e-02  9.91400929e-04  1.09208424e-02  3.40684429e-03\n",
      "  9.03945696e-03  2.44812062e-03  3.03581470e-04 -1.55190106e-02\n",
      "  2.72142777e-03  1.47783558e-02 -1.85200438e-03  2.13420401e-03\n",
      "  6.68267497e-03 -4.55261460e-03  1.14160835e-02 -7.17786318e-03\n",
      " -1.10781525e-02  5.76712193e-04  2.90887224e-03 -1.65065949e-02\n",
      " -1.70121971e-03 -3.58784874e-03 -5.92529232e-03 -4.06675031e-03]\n",
      "[-1.09323744e-05  1.93037766e-05 -2.49984500e-05 -3.05717448e-06\n",
      " -1.97070529e-06  2.66711846e-05 -3.11729764e-05  1.30327103e-05\n",
      "  1.94574848e-05  5.17478295e-06 -7.15217442e-06 -7.04173610e-07\n",
      "  2.56992328e-06 -1.05728614e-05  1.70554470e-05  1.71707534e-06\n",
      "  2.41591401e-06 -1.40311204e-05  7.94083903e-06 -1.16815405e-05\n",
      "  4.82010016e-06 -2.82646963e-06 -5.12736201e-06  9.99171054e-06\n",
      " -1.49494427e-05 -4.09449817e-06 -1.10381630e-05  3.10227933e-06\n",
      " -6.39568249e-06  6.30130019e-06 -1.88986047e-06 -6.32417896e-06\n",
      "  6.59421556e-07  5.85996573e-06  1.76712420e-05 -7.13984470e-06\n",
      "  2.80181108e-06 -1.45122259e-05  5.34358285e-06  4.78432805e-06\n",
      " -1.96888419e-05  1.39565900e-05 -6.18122734e-06  7.97914927e-06\n",
      "  1.09255282e-05 -6.40008424e-06  5.58089302e-06 -9.33765768e-06\n",
      " -5.85159893e-06 -8.13430441e-06  5.38799555e-06  1.83586504e-06\n",
      "  9.57053683e-06 -7.69168325e-06  2.75742449e-05 -2.21745128e-05\n",
      "  4.90096486e-06  2.75205918e-05 -2.75397237e-06 -3.06959063e-06\n",
      "  1.42209010e-05 -1.41801506e-06  2.94078284e-06  9.70220809e-06\n",
      "  6.37477332e-06 -6.01165439e-06  2.71461143e-06 -1.01428497e-05\n",
      " -2.81554521e-06  1.73886126e-05 -8.87531246e-06  1.31371703e-05\n",
      " -4.67923782e-06 -1.82180759e-05  1.08018260e-05 -1.20879226e-05\n",
      " -1.44136832e-05  1.92859735e-05 -2.23648931e-06 -2.83396227e-06\n",
      " -4.98260044e-06 -8.91823350e-06  7.29881466e-06 -4.67028751e-05\n",
      " -2.29363819e-06 -7.98343389e-07 -2.65420600e-06 -3.56578551e-05\n",
      " -1.36224557e-05 -2.19991102e-06 -1.51618205e-05 -9.42079575e-06\n",
      " -6.80208881e-06 -1.71203002e-06 -2.96315873e-05 -9.01529228e-06\n",
      "  1.33597389e-05 -5.49921165e-07  3.74506122e-07  1.75034264e-05\n",
      " -6.28891488e-07  7.71610743e-06  2.13581388e-06  3.73111099e-06\n",
      "  1.99576104e-05  1.14286772e-05  5.07206189e-06  9.47948296e-06\n",
      "  8.11064707e-06  1.47830730e-05  1.28879344e-06 -8.95890603e-06\n",
      " -7.95371413e-07 -8.63013651e-06 -9.18671212e-06 -3.34650893e-06\n",
      " -1.40509106e-05  2.35231793e-06 -5.46013066e-06  1.46479048e-05\n",
      "  2.28855689e-06 -1.19140405e-05 -1.96590228e-05  2.26509074e-05\n",
      " -1.19162895e-05  2.63052936e-06 -3.70633258e-06  1.09041859e-05\n",
      " -8.29895430e-06 -7.22865463e-07  2.02510416e-05  4.88922345e-07\n",
      " -2.39950313e-05  1.13642863e-05 -5.11965275e-06  2.95777986e-07\n",
      " -4.47251485e-06  1.87856182e-05  5.43072051e-06  1.55911290e-06\n",
      "  1.77400463e-06  2.72750235e-06 -2.44665119e-05  9.27383549e-06\n",
      "  1.79662981e-05 -6.77877659e-06 -6.93387927e-06 -4.32944713e-06\n",
      "  3.44173545e-05 -9.77415733e-06 -1.27269448e-06 -1.49065008e-05\n",
      "  3.83030349e-06  2.23376340e-05 -1.73587432e-06 -9.62198672e-06\n",
      "  1.42517456e-05  1.00860887e-05 -5.83665718e-06 -2.39794173e-06\n",
      "  1.91969791e-05  1.09415080e-05 -1.42572237e-05  1.84443230e-05\n",
      "  1.17361947e-06  1.63005130e-05 -1.63187574e-06 -1.34210311e-05\n",
      " -2.25415916e-05 -7.99787380e-07  1.10368902e-05 -2.67665301e-05\n",
      " -2.03899269e-06  1.74519486e-05  1.12329129e-06 -1.27577969e-05\n",
      "  2.51737957e-05  6.11084483e-06 -1.17366569e-05 -3.05046563e-06\n",
      "  1.74325303e-06  1.40405029e-05 -7.41159929e-06 -4.11849659e-05\n",
      " -6.16530642e-06 -3.65143348e-06 -8.64402252e-07 -5.14622873e-06\n",
      "  5.06189061e-06  6.48695682e-06 -3.26363279e-06 -1.41030380e-06]\n",
      "[1.06240973e-05 1.50785958e-05 4.51206151e-06 4.58643661e-06\n",
      " 1.84172896e-05 8.82467312e-06 1.74586168e-05 4.24464083e-06\n",
      " 2.78280078e-06 1.76811735e-05 1.90466546e-05 2.92522809e-05\n",
      " 5.83720091e-06 1.71555481e-05 1.15246368e-05 1.99354438e-05\n",
      " 8.68227438e-06 6.97748576e-06 1.29795812e-05 2.25626133e-05\n",
      " 1.92932823e-05 5.18215053e-06 8.54587491e-06 2.05138320e-05\n",
      " 1.88079573e-05 2.73843955e-05 4.28622008e-06 2.57019661e-05\n",
      " 1.52173323e-05 5.43020858e-06 9.81035504e-06 1.38113692e-05\n",
      " 3.70967918e-06 1.17825310e-05 1.54025104e-05 1.26221712e-05\n",
      " 6.88254955e-06 1.46071202e-06 1.51898989e-05 2.02876194e-05\n",
      " 4.96813945e-06 1.27828086e-05 1.76251923e-05 4.91639274e-06\n",
      " 2.30459154e-05 1.32390651e-05 1.05423462e-05 9.51406700e-06\n",
      " 1.07376950e-05 5.06787237e-06 2.33927024e-05 1.32685936e-05\n",
      " 1.35692756e-05 2.16019755e-05 2.28008926e-05 3.62216233e-05\n",
      " 1.22422297e-05 1.29287831e-05 2.78531692e-06 2.42039313e-05\n",
      " 1.33809388e-05 1.16241459e-05 1.54125612e-05 8.61076527e-06\n",
      " 4.72116533e-06 1.79993310e-05 5.79769875e-06 1.00377608e-05\n",
      " 1.67648654e-05 1.54880190e-05 4.68383656e-06 3.41688534e-05\n",
      " 9.96739873e-06 1.10977919e-05 1.34811362e-05 1.23539595e-05\n",
      " 1.05558720e-05 5.87387604e-06 6.45159522e-07 3.38102645e-05\n",
      " 1.51688876e-05 4.58073644e-06 2.37893088e-05 1.84796578e-05\n",
      " 1.56878261e-05 1.98107990e-05 1.05818817e-05 8.63979752e-06\n",
      " 1.34071248e-05 2.61350437e-05 7.91490255e-06 9.65897890e-06\n",
      " 5.47244185e-06 2.18087076e-05 6.03496470e-06 1.66133186e-05\n",
      " 2.24565023e-06 1.11233673e-05 1.34014463e-05 2.01678103e-05\n",
      " 4.42127705e-06 2.02103858e-05 1.86776635e-05 2.40615883e-05\n",
      " 1.63594053e-05 9.86551397e-06 5.23831079e-06 1.71902734e-05\n",
      " 1.01588920e-05 1.16076357e-05 1.73672013e-05 9.79587403e-06\n",
      " 9.34654996e-06 2.28301115e-05 1.13957103e-05 5.77054034e-06\n",
      " 5.98335070e-06 1.54751740e-05 1.03029962e-05 7.65170756e-06\n",
      " 1.36757342e-05 6.83722930e-06 2.45278125e-05 1.74959287e-05\n",
      " 5.79373292e-06 1.06746486e-05 2.89107720e-06 2.12553201e-05\n",
      " 1.69629283e-05 9.35743269e-06 2.45631633e-05 6.28369584e-06\n",
      " 2.84597549e-05 1.52335262e-05 9.76162331e-06 2.30413497e-05\n",
      " 8.17235824e-06 7.63037818e-06 1.13007066e-05 2.09959591e-05\n",
      " 2.84119125e-06 8.23288267e-06 4.45251599e-05 3.39730188e-06\n",
      " 1.03769140e-05 1.11296271e-05 1.13868764e-05 5.63186880e-06\n",
      " 3.64582943e-05 1.23197080e-05 1.47800699e-05 1.84915434e-05\n",
      " 8.45017944e-06 1.46024759e-05 1.46771596e-05 1.04007363e-05\n",
      " 5.53976299e-06 2.04150903e-05 1.13190022e-05 3.30913364e-05\n",
      " 9.83270393e-06 3.23610925e-06 3.05701788e-06 3.20169564e-05\n",
      " 1.51723298e-05 1.25041819e-06 1.47412871e-05 8.23013208e-06\n",
      " 6.91731913e-06 1.88941431e-05 8.89507034e-06 1.24235590e-05\n",
      " 3.54823360e-06 1.77931705e-05 3.80242333e-05 1.43390389e-05\n",
      " 1.06147060e-05 2.98813821e-06 1.01019802e-05 1.19206099e-05\n",
      " 5.46092169e-06 9.84932838e-06 1.13260447e-05 1.27700479e-05\n",
      " 6.47186748e-06 1.31333513e-05 1.50794563e-05 5.88090508e-06\n",
      " 1.05069612e-05 1.70868128e-05 1.17274296e-05 2.42179278e-05]\n",
      "[[ 0.04674514  0.08824236 -0.06639868 ... -0.07784942 -0.10045688\n",
      "   0.10320859]\n",
      " [-0.0573047   0.08669911  0.04996339 ...  0.06818534  0.00943867\n",
      "   0.008899  ]\n",
      " [-0.0684931   0.01716627  0.08504297 ...  0.00460122 -0.02581953\n",
      "  -0.11373648]\n",
      " ...\n",
      " [ 0.03822182 -0.02964856 -0.0456078  ...  0.12363642 -0.0565921\n",
      "   0.05715526]\n",
      " [ 0.04430542  0.08297257 -0.09968271 ... -0.05749648 -0.04641495\n",
      "  -0.03017745]\n",
      " [ 0.06462101  0.04115642 -0.04186402 ... -0.01883214 -0.06921361\n",
      "   0.01348803]]\n",
      "[[-4.30723415e-06  5.28049193e-06 -3.35882303e-06 ... -2.77060656e-06\n",
      "  -8.96723953e-07 -2.14628892e-06]\n",
      " [-2.09761808e-06  6.61634513e-07  1.97127575e-06 ...  2.62621042e-06\n",
      "  -2.25490864e-06 -3.19431240e-06]\n",
      " [ 3.95643692e-06 -1.88247745e-06 -2.08012544e-06 ... -1.00413791e-06\n",
      "   1.47149483e-06  5.47977306e-06]\n",
      " ...\n",
      " [ 4.52938073e-06 -4.62961525e-07 -3.67064032e-06 ... -6.57115010e-06\n",
      "   7.62935286e-07 -1.57068716e-06]\n",
      " [-5.91123633e-07 -2.51609098e-06  8.03121067e-06 ... -1.45504260e-06\n",
      "   1.37285079e-06 -4.29463881e-06]\n",
      " [ 3.30693070e-06  3.11304603e-06 -6.93491857e-06 ...  4.66078085e-06\n",
      "  -1.69298920e-06  6.06361197e-06]]\n",
      "[[1.54925851e-06 1.89014603e-06 3.54282524e-07 ... 5.14103673e-07\n",
      "  1.77927536e-06 1.23602397e-06]\n",
      " [5.50565375e-07 1.08973066e-06 1.64867301e-07 ... 5.10848350e-07\n",
      "  6.58686910e-07 1.28980465e-06]\n",
      " [1.38444057e-06 1.52481255e-06 2.76394310e-07 ... 3.49984036e-07\n",
      "  1.42408159e-06 7.30427985e-07]\n",
      " ...\n",
      " [1.01387300e-06 6.33724368e-07 3.61773254e-07 ... 4.63646666e-07\n",
      "  7.77370225e-07 6.65593428e-07]\n",
      " [1.61574600e-07 2.04652376e-07 1.39619928e-07 ... 5.49051586e-07\n",
      "  3.64559248e-07 8.80821013e-07]\n",
      " [6.57736413e-07 2.98962205e-07 2.86744307e-07 ... 3.58800603e-07\n",
      "  2.86282841e-07 4.69103894e-07]]\n",
      "[ 0.00923168  0.00131533 -0.0005905  -0.00961866 -0.00219373  0.01240358]\n",
      "[-2.87211365e-05 -1.27918489e-05  2.40820714e-05 -2.97902100e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -1.04696780e-05  5.76908020e-05]\n",
      "[1.40119504e-04 1.78948650e-04 2.14266897e-04 2.21220307e-04\n",
      " 3.60704829e-04 7.76961592e-05]\n",
      "[[ 0.11015707  0.13595913  0.02180584 -0.19201122  0.02636562  0.04513299]\n",
      " [ 0.09976395  0.06287592  0.04564913 -0.14641523  0.03470495  0.20655595]\n",
      " [ 0.1097784  -0.11438586  0.0537812   0.13174564  0.05247764 -0.09250314]\n",
      " ...\n",
      " [-0.18479816 -0.16995793 -0.03486537 -0.15786647  0.071494    0.16835531]\n",
      " [-0.02483635  0.04387176  0.03550074  0.17130226 -0.07611336 -0.01249736]\n",
      " [-0.00856523  0.01510721 -0.16020154  0.07957927  0.13123046 -0.24673255]]\n",
      "[[-6.03199183e-05 -3.25399677e-05 -3.48823851e-05  1.17408502e-04\n",
      "  -1.48002953e-05  2.51340644e-05]\n",
      " [-4.20400334e-05 -6.28582630e-05 -8.84215917e-05  1.47434513e-04\n",
      "   3.59313146e-06  4.22922441e-05]\n",
      " [-5.74874283e-05  7.31317945e-05  2.51347628e-04 -2.83476979e-04\n",
      "  -8.16249166e-06  2.46474762e-05]\n",
      " ...\n",
      " [ 7.34803158e-05  3.96926494e-05 -2.02543922e-06  1.65511018e-06\n",
      "  -5.97519900e-05 -5.30506462e-05]\n",
      " [ 5.01648843e-05  4.05615825e-05 -2.99613084e-05 -5.03069330e-05\n",
      "   6.54839341e-06 -1.70066189e-05]\n",
      " [-9.29659183e-06 -9.10421287e-06  4.76714853e-05 -1.79823716e-05\n",
      "  -4.79439175e-05  3.66556086e-05]]\n",
      "[[4.68257133e-05 2.32776094e-04 5.97987621e-05 1.20404233e-04\n",
      "  1.54804289e-04 2.75099966e-05]\n",
      " [2.95489123e-05 2.80209446e-05 4.79276598e-05 8.30288346e-05\n",
      "  6.18020214e-05 1.41660341e-05]\n",
      " [1.19488551e-05 1.06858543e-05 1.33776154e-05 1.85499126e-05\n",
      "  1.23139225e-05 7.77239486e-06]\n",
      " ...\n",
      " [6.52827224e-05 3.76681020e-05 7.46649661e-05 2.24843389e-05\n",
      "  9.50382503e-05 1.73655554e-05]\n",
      " [1.83563755e-05 2.73377687e-05 2.14774303e-05 4.44096327e-05\n",
      "  9.96692767e-05 1.26987938e-05]\n",
      " [1.32584450e-05 1.53747573e-05 3.79353128e-05 8.00874636e-06\n",
      "  1.46282928e-05 7.95089555e-06]]\n",
      "5.9345567e-35\n",
      "0.4731399\n",
      "747\n"
     ]
    }
   ],
   "source": [
    "names = classifier.get_variable_names()        \n",
    "print(\"name:\", names)\n",
    "for i in names:\n",
    "    print(classifier.get_variable_value(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = classifier.get_variable_value('ConvNet/conv2d/kernel')\n",
    "print(weights.shape)\n",
    "a=weights[0][0][0][0:25]\n",
    "b=a.reshape((5,5))\n",
    "plt.imshow(b, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "names = [\"KERNEL 1\", \"KERNEL 2\", \"KERNEL 3\", \"KERNEL 4\"]\n",
    "\n",
    "fig=plt.figure(figsize=(6, 6))\n",
    "columns = 2\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = trainData[i-1]*255\n",
    "    ax1 = fig.add_subplot(rows, columns, i)\n",
    "    ax1.set_title(names[trainTarget[i-1]])\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    a=weights[i][0][0][0:25]\n",
    "    b=a.reshape((5,5))\n",
    "    plt.imshow(b, cmap='gray')\n",
    "    plt.grid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
